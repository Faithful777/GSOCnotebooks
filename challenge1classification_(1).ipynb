{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ffe5f74",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-01T21:28:32.820153Z",
          "iopub.status.busy": "2024-04-01T21:28:32.819764Z",
          "iopub.status.idle": "2024-04-01T21:28:36.511310Z",
          "shell.execute_reply": "2024-04-01T21:28:36.509974Z"
        },
        "id": "0ffe5f74",
        "outputId": "e5770cb9-3af9-4a43-fd53-4f025a464b35",
        "papermill": {
          "duration": 3.705794,
          "end_time": "2024-04-01T21:28:36.513312",
          "exception": false,
          "start_time": "2024-04-01T21:28:32.807518",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f7b57e3",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-01T21:28:36.535659Z",
          "iopub.status.busy": "2024-04-01T21:28:36.535243Z",
          "iopub.status.idle": "2024-04-01T21:28:39.133810Z",
          "shell.execute_reply": "2024-04-01T21:28:39.132802Z"
        },
        "id": "3f7b57e3",
        "outputId": "8c72dfd4-65a8-4f25-9f92-33c71a9af1f5",
        "papermill": {
          "duration": 2.612373,
          "end_time": "2024-04-01T21:28:39.136396",
          "exception": false,
          "start_time": "2024-04-01T21:28:36.524023",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-04-01 21:28:37--  https://docs-assets.developer.apple.com/ml-research/models/fastvit/image_classification_models/fastvit_sa24.pth.tar\r\n",
            "Resolving docs-assets.developer.apple.com (docs-assets.developer.apple.com)... 17.253.31.204, 17.253.31.203, 2620:149:a06:f000::1, ...\r\n",
            "Connecting to docs-assets.developer.apple.com (docs-assets.developer.apple.com)|17.253.31.204|:443... connected.\r\n",
            "HTTP request sent, awaiting response... 200 OK\r\n",
            "Length: 86767065 (83M) [application/x-tar]\r\n",
            "Saving to: '/content/fastvit_sa24.pth.tar'\r\n",
            "\r\n",
            "fastvit_sa24.pth.ta 100%[===================>]  82.75M  58.5MB/s    in 1.4s    \r\n",
            "\r\n",
            "2024-04-01 21:28:39 (58.5 MB/s) - '/content/fastvit_sa24.pth.tar' saved [86767065/86767065]\r\n",
            "\r\n"
          ]
        }
      ],
      "source": [
        "# Download a file and save it to a specific folder\n",
        "!wget https://docs-assets.developer.apple.com/ml-research/models/fastvit/image_classification_models/fastvit_sa24.pth.tar -P /content/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eec8feb8",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-01T21:28:39.162137Z",
          "iopub.status.busy": "2024-04-01T21:28:39.161229Z",
          "iopub.status.idle": "2024-04-01T21:29:01.918199Z",
          "shell.execute_reply": "2024-04-01T21:29:01.917178Z"
        },
        "id": "eec8feb8",
        "outputId": "99f7ad7b-e60f-4ff3-b04d-6a0be1ee106b",
        "papermill": {
          "duration": 22.772374,
          "end_time": "2024-04-01T21:29:01.920845",
          "exception": false,
          "start_time": "2024-04-01T21:28:39.148471",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting gdown\r\n",
            "  Downloading gdown-5.1.0-py3-none-any.whl.metadata (5.7 kB)\r\n",
            "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from gdown) (4.12.2)\r\n",
            "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from gdown) (3.13.1)\r\n",
            "Requirement already satisfied: requests[socks] in /opt/conda/lib/python3.10/site-packages (from gdown) (2.31.0)\r\n",
            "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from gdown) (4.66.1)\r\n",
            "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->gdown) (2.5)\r\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.3.2)\r\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.6)\r\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.26.18)\r\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (2024.2.2)\r\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.7.1)\r\n",
            "Downloading gdown-5.1.0-py3-none-any.whl (17 kB)\r\n",
            "Installing collected packages: gdown\r\n",
            "Successfully installed gdown-5.1.0\r\n",
            "Downloading...\r\n",
            "From (original): https://drive.google.com/uc?id=1ZEyNMEO43u3qhJAwJeBZxFBEYc_pVYZQ\r\n",
            "From (redirected): https://drive.google.com/uc?id=1ZEyNMEO43u3qhJAwJeBZxFBEYc_pVYZQ&confirm=t&uuid=f8ca3b92-0905-4de8-92e9-685d142bc3fc\r\n",
            "To: /kaggle/working/dataset.zip\r\n",
            "100%|███████████████████████████████████████| 1.13G/1.13G [00:06<00:00, 162MB/s]\r\n"
          ]
        }
      ],
      "source": [
        "!pip install gdown\n",
        "!gdown --fuzzy https://drive.google.com/file/d/1ZEyNMEO43u3qhJAwJeBZxFBEYc_pVYZQ/view?usp=sharing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7e1e6ff",
      "metadata": {
        "id": "e7e1e6ff",
        "papermill": {
          "duration": 0.01614,
          "end_time": "2024-04-01T21:29:01.953612",
          "exception": false,
          "start_time": "2024-04-01T21:29:01.937472",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "Import Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0001127",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-01T21:29:01.989091Z",
          "iopub.status.busy": "2024-04-01T21:29:01.988245Z",
          "iopub.status.idle": "2024-04-01T21:29:05.284734Z",
          "shell.execute_reply": "2024-04-01T21:29:05.283929Z"
        },
        "id": "a0001127",
        "papermill": {
          "duration": 3.31623,
          "end_time": "2024-04-01T21:29:05.286990",
          "exception": false,
          "start_time": "2024-04-01T21:29:01.970760",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from skimage import exposure\n",
        "from scipy.ndimage import gaussian_filter\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import transforms\n",
        "\n",
        "current_directory = os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db51a42e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-01T21:29:05.322278Z",
          "iopub.status.busy": "2024-04-01T21:29:05.321245Z",
          "iopub.status.idle": "2024-04-01T21:29:49.047395Z",
          "shell.execute_reply": "2024-04-01T21:29:49.046231Z"
        },
        "id": "db51a42e",
        "papermill": {
          "duration": 43.746121,
          "end_time": "2024-04-01T21:29:49.049730",
          "exception": false,
          "start_time": "2024-04-01T21:29:05.303609",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Extract the downloaded zip file into the /content directory\n",
        "!unzip -q /$(pwd)/dataset.zip -d /$(pwd)/\n",
        "\n",
        "# Remove the downloaded zip file (optional)\n",
        "!rm /$(pwd)/dataset.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4188fe3",
      "metadata": {
        "id": "c4188fe3",
        "papermill": {
          "duration": 0.016441,
          "end_time": "2024-04-01T21:29:49.083189",
          "exception": false,
          "start_time": "2024-04-01T21:29:49.066748",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "### Models Brief\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50a1c1ad",
      "metadata": {
        "id": "50a1c1ad",
        "papermill": {
          "duration": 0.016666,
          "end_time": "2024-04-01T21:29:49.116570",
          "exception": false,
          "start_time": "2024-04-01T21:29:49.099904",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "We use two models for this project\n",
        "\n",
        "**FastViT SA24 Architecture: A Breakdown**\n",
        "\n",
        "FastViT SA24 is a lightweight variant of the Vision Transformer (ViT) architecture designed for efficient image classification. Here's a detailed breakdown of its key aspects based on the information provided:\n",
        "\n",
        "**Overall Structure:**\n",
        "\n",
        "* FastViT SA24 follows a hybrid transformer approach, combining convolutional layers with transformer components.\n",
        "* It processes the image through four distinct stages operating at different scales.\n",
        "\n",
        "**Stages:**\n",
        "\n",
        "* Each stage utilizes a similar architecture except for the final stage (stage 4).\n",
        "* Stages 1, 2, and 3 rely on a novel technique called RepMixer for token mixing, which improves efficiency by reparameterizing skip connections.\n",
        "* Stage 4 leverages self-attention layers for token mixing, typically used in standard ViT models.\n",
        "\n",
        "**Key Techniques for Efficiency:**\n",
        "\n",
        "* **RepMixer:** This method rearranges operations in the skip connection within a residual block, allowing for a single depthwise convolution at inference, reducing computational cost.\n",
        "* **Factorized Dense Convolutions:** Dense convolutions are replaced with a combination of depthwise and pointwise convolutions, lowering parameter count and FLOPs (Floating-Point Operations).\n",
        "* **Train-Time Overparameterization:** Linear overparameterization is applied during training to compensate for the efficiency gains from factorized convolutions, ultimately improving model performance.\n",
        "* **Large Kernel Convolutions:** Depthwise convolutions with larger kernels (like 7x7) are incorporated in the early stages (FFN and patch embedding layers) to improve receptive field (the area an element in the network \"sees\") without the high cost of self-attention.\n",
        "\n",
        "**Benefits:**\n",
        "\n",
        "* FastViT SA24 offers significant computational efficiency compared to the base ViT model, making it suitable for deployment on resource-constrained devices.\n",
        "* It achieves accuracy levels competitive with some ViT models while requiring lower FLOPs and memory footprint.\n",
        "\n",
        "**Trade-offs:**\n",
        "\n",
        "* There might be a slight trade-off in terms of top-accuracy compared to larger ViT models.\n",
        "* Train-time can be slightly increased due to the additional computations involved in overparameterization.\n",
        "\n",
        "**Applications:**\n",
        "\n",
        "* FastViT SA24 is well-suited for scenarios where:\n",
        "    * Fast training and inference are crucial.\n",
        "    * Computational resources are limited (e.g., mobile devices, embedded systems).\n",
        "\n",
        "**Comparison with PoolFormer Baseline:**\n",
        "\n",
        "The provided information compares FastViT SA24 with a PoolFormer baseline model. It highlights how each architectural choice in FastViT contributes to improved efficiency and performance:\n",
        "\n",
        "* RepMixer significantly reduces latency, especially at higher resolutions.\n",
        "* Factorized convolutions and train-time overparameterization lead to lower parameter count and FLOPs while maintaining accuracy.\n",
        "* Large kernel convolutions provide a good balance between receptive field and computational cost.\n",
        "\n",
        "https://arxiv.org/pdf/2303.14189v2.pdf\n",
        "\n",
        "\n",
        "**DeiT-B 384: Architecture with Distillation**\n",
        "\n",
        "DeiT-B 384 is a pre-trained image classification model based on the Vision Transformer (ViT) architecture. It leverages a technique called knowledge distillation to improve its performance on image recognition tasks. Here's a breakdown of the key aspects based on the information provided:\n",
        "\n",
        "**Knowledge Distillation:**\n",
        "\n",
        "* This technique involves transferring knowledge from a pre-trained \"teacher\" model (often a convolutional neural network) to a smaller \"student\" model (DeiT-B in this case).\n",
        "* By learning from the teacher's outputs, the student model can achieve better accuracy despite having fewer parameters.\n",
        "\n",
        "**DeiT-B Architecture:**\n",
        "\n",
        "* The core architecture of DeiT-B is likely the same as the ViT-B model, which relies on transformer blocks for image classification.\n",
        "* These blocks use self-attention mechanisms to learn relationships between different parts of an image.\n",
        "* DeiT-B is specifically fine-tuned for a resolution of 384x384 pixels.\n",
        "\n",
        "**Distillation Token:**\n",
        "\n",
        "* DeiT-B incorporates a novel element called the \"distillation token.\"\n",
        "* This token is added to the initial set of embeddings processed by the model alongside the patch tokens (representing image regions) and the class token (representing the overall image class).\n",
        "* The distillation token interacts with other tokens through self-attention layers, similar to the class token.\n",
        "\n",
        "**Distillation Loss:**\n",
        "\n",
        "* During training, the model is presented with both the true image label and the predicted label from the teacher model.\n",
        "* A special loss function is calculated based on the outputs of the class token and the distillation token.\n",
        "    * This loss encourages the model's outputs to align with both the true label and the teacher's prediction.\n",
        "* The model learns to combine information from both sources, ultimately improving its classification accuracy.\n",
        "\n",
        "**Key Points:**\n",
        "\n",
        "* DeiT-B 384 leverages knowledge distillation to achieve high performance despite being a relatively lightweight model.\n",
        "* The distillation token acts as a bridge between the student model and the teacher model, facilitating knowledge transfer.\n",
        "* The model utilizes both the true label and the teacher's prediction during training, leading to more robust performance.\n",
        "\n",
        "https://arxiv.org/pdf/2012.12877v2.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "795aa3d2",
      "metadata": {
        "id": "795aa3d2",
        "papermill": {
          "duration": 0.016663,
          "end_time": "2024-04-01T21:29:49.150440",
          "exception": false,
          "start_time": "2024-04-01T21:29:49.133777",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "### Important functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0bdb48ec",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-01T21:29:49.186169Z",
          "iopub.status.busy": "2024-04-01T21:29:49.185372Z",
          "iopub.status.idle": "2024-04-01T21:29:49.202086Z",
          "shell.execute_reply": "2024-04-01T21:29:49.201163Z"
        },
        "id": "0bdb48ec",
        "papermill": {
          "duration": 0.037247,
          "end_time": "2024-04-01T21:29:49.204380",
          "exception": false,
          "start_time": "2024-04-01T21:29:49.167133",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "import warnings\n",
        "\n",
        "\n",
        "def drop_path(x, drop_prob: float = 0., training: bool = False, scale_by_keep: bool = True):\n",
        "    \"\"\"Drop paths (Stochastic Depth) per sample (when applied in main path of residual blocks).\n",
        "\n",
        "    This is the same as the DropConnect impl I created for EfficientNet, etc networks, however,\n",
        "    the original name is misleading as 'Drop Connect' is a different form of dropout in a separate paper...\n",
        "    See discussion: https://github.com/tensorflow/tpu/issues/494#issuecomment-532968956 ... I've opted for\n",
        "    changing the layer and argument names to 'drop path' rather than mix DropConnect as a layer name and use\n",
        "    'survival rate' as the argument.\n",
        "\n",
        "    \"\"\"\n",
        "    if drop_prob == 0. or not training:\n",
        "        return x\n",
        "    keep_prob = 1 - drop_prob\n",
        "    shape = (x.shape[0],) + (1,) * (x.ndim - 1)  # work with diff dim tensors, not just 2D ConvNets\n",
        "    random_tensor = x.new_empty(shape).bernoulli_(keep_prob)\n",
        "    if keep_prob > 0.0 and scale_by_keep:\n",
        "        random_tensor.div_(keep_prob)\n",
        "    return x * random_tensor\n",
        "\n",
        "\n",
        "def _no_grad_trunc_normal_(tensor, mean, std, a, b):\n",
        "    # Cut & paste from PyTorch official master until it's in a few official releases - RW\n",
        "    # Method based on https://people.sc.fsu.edu/~jburkardt/presentations/truncated_normal.pdf\n",
        "    def norm_cdf(x):\n",
        "        # Computes standard normal cumulative distribution function\n",
        "        return (1. + math.erf(x / math.sqrt(2.))) / 2.\n",
        "\n",
        "    if (mean < a - 2 * std) or (mean > b + 2 * std):\n",
        "        warnings.warn(\"mean is more than 2 std from [a, b] in nn.init.trunc_normal_. \"\n",
        "                      \"The distribution of values may be incorrect.\",\n",
        "                      stacklevel=2)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Values are generated by using a truncated uniform distribution and\n",
        "        # then using the inverse CDF for the normal distribution.\n",
        "        # Get upper and lower cdf values\n",
        "        l = norm_cdf((a - mean) / std)\n",
        "        u = norm_cdf((b - mean) / std)\n",
        "\n",
        "        # Uniformly fill tensor with values from [l, u], then translate to\n",
        "        # [2l-1, 2u-1].\n",
        "        tensor.uniform_(2 * l - 1, 2 * u - 1)\n",
        "\n",
        "        # Use inverse cdf transform for normal distribution to get truncated\n",
        "        # standard normal\n",
        "        tensor.erfinv_()\n",
        "\n",
        "        # Transform to proper mean, std\n",
        "        tensor.mul_(std * math.sqrt(2.))\n",
        "        tensor.add_(mean)\n",
        "\n",
        "        # Clamp to ensure it's in the proper range\n",
        "        tensor.clamp_(min=a, max=b)\n",
        "        return tensor\n",
        "\n",
        "\n",
        "def trunc_normal_(tensor, mean=0., std=1., a=-2., b=2.):\n",
        "    # type: (Tensor, float, float, float, float) -> Tensor\n",
        "    r\"\"\"Fills the input Tensor with values drawn from a truncated\n",
        "    normal distribution. The values are effectively drawn from the\n",
        "    normal distribution :math:`\\mathcal{N}(\\text{mean}, \\text{std}^2)`\n",
        "    with values outside :math:`[a, b]` redrawn until they are within\n",
        "    the bounds. The method used for generating the random values works\n",
        "    best when :math:`a \\leq \\text{mean} \\leq b`.\n",
        "    Args:\n",
        "        tensor: an n-dimensional `torch.Tensor`\n",
        "        mean: the mean of the normal distribution\n",
        "        std: the standard deviation of the normal distribution\n",
        "        a: the minimum cutoff value\n",
        "        b: the maximum cutoff value\n",
        "    Examples:\n",
        "        >>> w = torch.empty(3, 5)\n",
        "        >>> nn.init.trunc_normal_(w)\n",
        "    \"\"\"\n",
        "    return _no_grad_trunc_normal_(tensor, mean, std, a, b)\n",
        "\n",
        "class DropPath(nn.Module):\n",
        "    \"\"\"Drop paths (Stochastic Depth) per sample  (when applied in main path of residual blocks).\n",
        "    \"\"\"\n",
        "    def __init__(self, drop_prob=None, scale_by_keep=True):\n",
        "        super(DropPath, self).__init__()\n",
        "        self.drop_prob = drop_prob\n",
        "        self.scale_by_keep = scale_by_keep\n",
        "\n",
        "    def forward(self, x):\n",
        "        return drop_path(x, self.drop_prob, self.training, self.scale_by_keep)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6da823f3",
      "metadata": {
        "id": "6da823f3",
        "papermill": {
          "duration": 0.016142,
          "end_time": "2024-04-01T21:29:49.238036",
          "exception": false,
          "start_time": "2024-04-01T21:29:49.221894",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "### Mobile One"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3faf10fc",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-01T21:29:49.271829Z",
          "iopub.status.busy": "2024-04-01T21:29:49.271358Z",
          "iopub.status.idle": "2024-04-01T21:29:49.329036Z",
          "shell.execute_reply": "2024-04-01T21:29:49.328297Z"
        },
        "id": "3faf10fc",
        "papermill": {
          "duration": 0.077094,
          "end_time": "2024-04-01T21:29:49.331097",
          "exception": false,
          "start_time": "2024-04-01T21:29:49.254003",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "#\n",
        "# For licensing see accompanying LICENSE file.\n",
        "# Copyright (C) 2022 Apple Inc. All Rights Reserved.\n",
        "#\n",
        "from typing import Optional, List, Tuple\n",
        "\n",
        "import copy\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "__all__ = ['MobileOne', 'mobileone', 'reparameterize_model']\n",
        "\n",
        "\n",
        "class SEBlock(nn.Module):\n",
        "    \"\"\" Squeeze and Excite module.\n",
        "\n",
        "        Pytorch implementation of `Squeeze-and-Excitation Networks` -\n",
        "        https://arxiv.org/pdf/1709.01507.pdf\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 in_channels: int,\n",
        "                 rd_ratio: float = 0.0625) -> None:\n",
        "        \"\"\" Construct a Squeeze and Excite Module.\n",
        "\n",
        "        :param in_channels: Number of input channels.\n",
        "        :param rd_ratio: Input channel reduction ratio.\n",
        "        \"\"\"\n",
        "        super(SEBlock, self).__init__()\n",
        "        self.reduce = nn.Conv2d(in_channels=in_channels,\n",
        "                                out_channels=int(in_channels * rd_ratio),\n",
        "                                kernel_size=1,\n",
        "                                stride=1,\n",
        "                                bias=True)\n",
        "        self.expand = nn.Conv2d(in_channels=int(in_channels * rd_ratio),\n",
        "                                out_channels=in_channels,\n",
        "                                kernel_size=1,\n",
        "                                stride=1,\n",
        "                                bias=True)\n",
        "\n",
        "    def forward(self, inputs: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\" Apply forward pass. \"\"\"\n",
        "        b, c, h, w = inputs.size()\n",
        "        x = F.avg_pool2d(inputs, kernel_size=[h, w])\n",
        "        x = self.reduce(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.expand(x)\n",
        "        x = torch.sigmoid(x)\n",
        "        x = x.view(-1, c, 1, 1)\n",
        "        return inputs * x\n",
        "\n",
        "\n",
        "class MobileOneBlock(nn.Module):\n",
        "    \"\"\" MobileOne building block.\n",
        "\n",
        "        This block has a multi-branched architecture at train-time\n",
        "        and plain-CNN style architecture at inference time\n",
        "        For more details, please refer to our paper:\n",
        "        `An Improved One millisecond Mobile Backbone` -\n",
        "        https://arxiv.org/pdf/2206.04040.pdf\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 in_channels: int,\n",
        "                 out_channels: int,\n",
        "                 kernel_size: int,\n",
        "                 stride: int = 1,\n",
        "                 padding: int = 0,\n",
        "                 dilation: int = 1,\n",
        "                 groups: int = 1,\n",
        "                 inference_mode: bool = False,\n",
        "                 use_se: bool = False,\n",
        "                 num_conv_branches: int = 1) -> None:\n",
        "        \"\"\" Construct a MobileOneBlock module.\n",
        "\n",
        "        :param in_channels: Number of channels in the input.\n",
        "        :param out_channels: Number of channels produced by the block.\n",
        "        :param kernel_size: Size of the convolution kernel.\n",
        "        :param stride: Stride size.\n",
        "        :param padding: Zero-padding size.\n",
        "        :param dilation: Kernel dilation factor.\n",
        "        :param groups: Group number.\n",
        "        :param inference_mode: If True, instantiates model in inference mode.\n",
        "        :param use_se: Whether to use SE-ReLU activations.\n",
        "        :param num_conv_branches: Number of linear conv branches.\n",
        "        \"\"\"\n",
        "        super(MobileOneBlock, self).__init__()\n",
        "        self.inference_mode = inference_mode\n",
        "        self.groups = groups\n",
        "        self.stride = stride\n",
        "        self.kernel_size = kernel_size\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.num_conv_branches = num_conv_branches\n",
        "\n",
        "        # Check if SE-ReLU is requested\n",
        "        if use_se:\n",
        "            self.se = SEBlock(out_channels)\n",
        "        else:\n",
        "            self.se = nn.Identity()\n",
        "        self.activation = nn.ReLU()\n",
        "\n",
        "        if inference_mode:\n",
        "            self.reparam_conv = nn.Conv2d(in_channels=in_channels,\n",
        "                                          out_channels=out_channels,\n",
        "                                          kernel_size=kernel_size,\n",
        "                                          stride=stride,\n",
        "                                          padding=padding,\n",
        "                                          dilation=dilation,\n",
        "                                          groups=groups,\n",
        "                                          bias=True)\n",
        "        else:\n",
        "            # Re-parameterizable skip connection\n",
        "            self.rbr_skip = nn.BatchNorm2d(num_features=in_channels) \\\n",
        "                if out_channels == in_channels and stride == 1 else None\n",
        "\n",
        "            # Re-parameterizable conv branches\n",
        "            rbr_conv = list()\n",
        "            for _ in range(self.num_conv_branches):\n",
        "                rbr_conv.append(self._conv_bn(kernel_size=kernel_size,\n",
        "                                              padding=padding))\n",
        "            self.rbr_conv = nn.ModuleList(rbr_conv)\n",
        "\n",
        "            # Re-parameterizable scale branch\n",
        "            self.rbr_scale = None\n",
        "            if kernel_size > 1:\n",
        "                self.rbr_scale = self._conv_bn(kernel_size=1,\n",
        "                                               padding=0)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\" Apply forward pass. \"\"\"\n",
        "        # Inference mode forward pass.\n",
        "        if self.inference_mode:\n",
        "            return self.activation(self.se(self.reparam_conv(x)))\n",
        "\n",
        "        # Multi-branched train-time forward pass.\n",
        "        # Skip branch output\n",
        "        identity_out = 0\n",
        "        if self.rbr_skip is not None:\n",
        "            identity_out = self.rbr_skip(x)\n",
        "\n",
        "        # Scale branch output\n",
        "        scale_out = 0\n",
        "        if self.rbr_scale is not None:\n",
        "            scale_out = self.rbr_scale(x)\n",
        "\n",
        "        # Other branches\n",
        "        out = scale_out + identity_out\n",
        "        for ix in range(self.num_conv_branches):\n",
        "            out += self.rbr_conv[ix](x)\n",
        "\n",
        "        return self.activation(self.se(out))\n",
        "\n",
        "    def reparameterize(self):\n",
        "        \"\"\" Following works like `RepVGG: Making VGG-style ConvNets Great Again` -\n",
        "        https://arxiv.org/pdf/2101.03697.pdf. We re-parameterize multi-branched\n",
        "        architecture used at training time to obtain a plain CNN-like structure\n",
        "        for inference.\n",
        "        \"\"\"\n",
        "        if self.inference_mode:\n",
        "            return\n",
        "        kernel, bias = self._get_kernel_bias()\n",
        "        self.reparam_conv = nn.Conv2d(in_channels=self.rbr_conv[0].conv.in_channels,\n",
        "                                      out_channels=self.rbr_conv[0].conv.out_channels,\n",
        "                                      kernel_size=self.rbr_conv[0].conv.kernel_size,\n",
        "                                      stride=self.rbr_conv[0].conv.stride,\n",
        "                                      padding=self.rbr_conv[0].conv.padding,\n",
        "                                      dilation=self.rbr_conv[0].conv.dilation,\n",
        "                                      groups=self.rbr_conv[0].conv.groups,\n",
        "                                      bias=True)\n",
        "        self.reparam_conv.weight.data = kernel\n",
        "        self.reparam_conv.bias.data = bias\n",
        "\n",
        "        # Delete un-used branches\n",
        "        for para in self.parameters():\n",
        "            para.detach_()\n",
        "        self.__delattr__('rbr_conv')\n",
        "        self.__delattr__('rbr_scale')\n",
        "        if hasattr(self, 'rbr_skip'):\n",
        "            self.__delattr__('rbr_skip')\n",
        "\n",
        "        self.inference_mode = True\n",
        "\n",
        "    def _get_kernel_bias(self) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        \"\"\" Method to obtain re-parameterized kernel and bias.\n",
        "        Reference: https://github.com/DingXiaoH/RepVGG/blob/main/repvgg.py#L83\n",
        "\n",
        "        :return: Tuple of (kernel, bias) after fusing branches.\n",
        "        \"\"\"\n",
        "        # get weights and bias of scale branch\n",
        "        kernel_scale = 0\n",
        "        bias_scale = 0\n",
        "        if self.rbr_scale is not None:\n",
        "            kernel_scale, bias_scale = self._fuse_bn_tensor(self.rbr_scale)\n",
        "            # Pad scale branch kernel to match conv branch kernel size.\n",
        "            pad = self.kernel_size // 2\n",
        "            kernel_scale = torch.nn.functional.pad(kernel_scale,\n",
        "                                                   [pad, pad, pad, pad])\n",
        "\n",
        "        # get weights and bias of skip branch\n",
        "        kernel_identity = 0\n",
        "        bias_identity = 0\n",
        "        if self.rbr_skip is not None:\n",
        "            kernel_identity, bias_identity = self._fuse_bn_tensor(self.rbr_skip)\n",
        "\n",
        "        # get weights and bias of conv branches\n",
        "        kernel_conv = 0\n",
        "        bias_conv = 0\n",
        "        for ix in range(self.num_conv_branches):\n",
        "            _kernel, _bias = self._fuse_bn_tensor(self.rbr_conv[ix])\n",
        "            kernel_conv += _kernel\n",
        "            bias_conv += _bias\n",
        "\n",
        "        kernel_final = kernel_conv + kernel_scale + kernel_identity\n",
        "        bias_final = bias_conv + bias_scale + bias_identity\n",
        "        return kernel_final, bias_final\n",
        "\n",
        "    def _fuse_bn_tensor(self, branch) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        \"\"\" Method to fuse batchnorm layer with preceeding conv layer.\n",
        "        Reference: https://github.com/DingXiaoH/RepVGG/blob/main/repvgg.py#L95\n",
        "\n",
        "        :param branch:\n",
        "        :return: Tuple of (kernel, bias) after fusing batchnorm.\n",
        "        \"\"\"\n",
        "        if isinstance(branch, nn.Sequential):\n",
        "            kernel = branch.conv.weight\n",
        "            running_mean = branch.bn.running_mean\n",
        "            running_var = branch.bn.running_var\n",
        "            gamma = branch.bn.weight\n",
        "            beta = branch.bn.bias\n",
        "            eps = branch.bn.eps\n",
        "        else:\n",
        "            assert isinstance(branch, nn.BatchNorm2d)\n",
        "            if not hasattr(self, 'id_tensor'):\n",
        "                input_dim = self.in_channels // self.groups\n",
        "                kernel_value = torch.zeros((self.in_channels,\n",
        "                                            input_dim,\n",
        "                                            self.kernel_size,\n",
        "                                            self.kernel_size),\n",
        "                                           dtype=branch.weight.dtype,\n",
        "                                           device=branch.weight.device)\n",
        "                for i in range(self.in_channels):\n",
        "                    kernel_value[i, i % input_dim,\n",
        "                                 self.kernel_size // 2,\n",
        "                                 self.kernel_size // 2] = 1\n",
        "                self.id_tensor = kernel_value\n",
        "            kernel = self.id_tensor\n",
        "            running_mean = branch.running_mean\n",
        "            running_var = branch.running_var\n",
        "            gamma = branch.weight\n",
        "            beta = branch.bias\n",
        "            eps = branch.eps\n",
        "        std = (running_var + eps).sqrt()\n",
        "        t = (gamma / std).reshape(-1, 1, 1, 1)\n",
        "        return kernel * t, beta - running_mean * gamma / std\n",
        "\n",
        "    def _conv_bn(self,\n",
        "                 kernel_size: int,\n",
        "                 padding: int) -> nn.Sequential:\n",
        "        \"\"\" Helper method to construct conv-batchnorm layers.\n",
        "\n",
        "        :param kernel_size: Size of the convolution kernel.\n",
        "        :param padding: Zero-padding size.\n",
        "        :return: Conv-BN module.\n",
        "        \"\"\"\n",
        "        mod_list = nn.Sequential()\n",
        "        mod_list.add_module('conv', nn.Conv2d(in_channels=self.in_channels,\n",
        "                                              out_channels=self.out_channels,\n",
        "                                              kernel_size=kernel_size,\n",
        "                                              stride=self.stride,\n",
        "                                              padding=padding,\n",
        "                                              groups=self.groups,\n",
        "                                              bias=False))\n",
        "        mod_list.add_module('bn', nn.BatchNorm2d(num_features=self.out_channels))\n",
        "        return mod_list\n",
        "\n",
        "\n",
        "class MobileOne(nn.Module):\n",
        "    \"\"\" MobileOne Model\n",
        "\n",
        "        Pytorch implementation of `An Improved One millisecond Mobile Backbone` -\n",
        "        https://arxiv.org/pdf/2206.04040.pdf\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 num_blocks_per_stage: List[int] = [2, 8, 10, 1],\n",
        "                 num_classes: int = 1000,\n",
        "                 width_multipliers: Optional[List[float]] = None,\n",
        "                 inference_mode: bool = False,\n",
        "                 use_se: bool = False,\n",
        "                 num_conv_branches: int = 1) -> None:\n",
        "        \"\"\" Construct MobileOne model.\n",
        "\n",
        "        :param num_blocks_per_stage: List of number of blocks per stage.\n",
        "        :param num_classes: Number of classes in the dataset.\n",
        "        :param width_multipliers: List of width multiplier for blocks in a stage.\n",
        "        :param inference_mode: If True, instantiates model in inference mode.\n",
        "        :param use_se: Whether to use SE-ReLU activations.\n",
        "        :param num_conv_branches: Number of linear conv branches.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        assert len(width_multipliers) == 4\n",
        "        self.inference_mode = inference_mode\n",
        "        self.in_planes = min(64, int(64 * width_multipliers[0]))\n",
        "        self.use_se = use_se\n",
        "        self.num_conv_branches = num_conv_branches\n",
        "\n",
        "        # Build stages\n",
        "        self.stage0 = MobileOneBlock(in_channels=3, out_channels=self.in_planes,\n",
        "                                     kernel_size=3, stride=2, padding=1,\n",
        "                                     inference_mode=self.inference_mode)\n",
        "        self.cur_layer_idx = 1\n",
        "        self.stage1 = self._make_stage(int(64 * width_multipliers[0]), num_blocks_per_stage[0],\n",
        "                                       num_se_blocks=0)\n",
        "        self.stage2 = self._make_stage(int(128 * width_multipliers[1]), num_blocks_per_stage[1],\n",
        "                                       num_se_blocks=0)\n",
        "        self.stage3 = self._make_stage(int(256 * width_multipliers[2]), num_blocks_per_stage[2],\n",
        "                                       num_se_blocks=int(num_blocks_per_stage[2] // 2) if use_se else 0)\n",
        "        self.stage4 = self._make_stage(int(512 * width_multipliers[3]), num_blocks_per_stage[3],\n",
        "                                       num_se_blocks=num_blocks_per_stage[3] if use_se else 0)\n",
        "        self.gap = nn.AdaptiveAvgPool2d(output_size=1)\n",
        "        self.linear = nn.Linear(int(512 * width_multipliers[3]), num_classes)\n",
        "\n",
        "    def _make_stage(self,\n",
        "                    planes: int,\n",
        "                    num_blocks: int,\n",
        "                    num_se_blocks: int) -> nn.Sequential:\n",
        "        \"\"\" Build a stage of MobileOne model.\n",
        "\n",
        "        :param planes: Number of output channels.\n",
        "        :param num_blocks: Number of blocks in this stage.\n",
        "        :param num_se_blocks: Number of SE blocks in this stage.\n",
        "        :return: A stage of MobileOne model.\n",
        "        \"\"\"\n",
        "        # Get strides for all layers\n",
        "        strides = [2] + [1]*(num_blocks-1)\n",
        "        blocks = []\n",
        "        for ix, stride in enumerate(strides):\n",
        "            use_se = False\n",
        "            if num_se_blocks > num_blocks:\n",
        "                raise ValueError(\"Number of SE blocks cannot \"\n",
        "                                 \"exceed number of layers.\")\n",
        "            if ix >= (num_blocks - num_se_blocks):\n",
        "                use_se = True\n",
        "\n",
        "            # Depthwise conv\n",
        "            blocks.append(MobileOneBlock(in_channels=self.in_planes,\n",
        "                                         out_channels=self.in_planes,\n",
        "                                         kernel_size=3,\n",
        "                                         stride=stride,\n",
        "                                         padding=1,\n",
        "                                         groups=self.in_planes,\n",
        "                                         inference_mode=self.inference_mode,\n",
        "                                         use_se=use_se,\n",
        "                                         num_conv_branches=self.num_conv_branches))\n",
        "            # Pointwise conv\n",
        "            blocks.append(MobileOneBlock(in_channels=self.in_planes,\n",
        "                                         out_channels=planes,\n",
        "                                         kernel_size=1,\n",
        "                                         stride=1,\n",
        "                                         padding=0,\n",
        "                                         groups=1,\n",
        "                                         inference_mode=self.inference_mode,\n",
        "                                         use_se=use_se,\n",
        "                                         num_conv_branches=self.num_conv_branches))\n",
        "            self.in_planes = planes\n",
        "            self.cur_layer_idx += 1\n",
        "        return nn.Sequential(*blocks)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\" Apply forward pass. \"\"\"\n",
        "        x = self.stage0(x)\n",
        "        x = self.stage1(x)\n",
        "        x = self.stage2(x)\n",
        "        x = self.stage3(x)\n",
        "        x = self.stage4(x)\n",
        "        x = self.gap(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.linear(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "PARAMS = {\n",
        "    \"s0\": {\"width_multipliers\": (0.75, 1.0, 1.0, 2.0),\n",
        "           \"num_conv_branches\": 4},\n",
        "    \"s1\": {\"width_multipliers\": (1.5, 1.5, 2.0, 2.5)},\n",
        "    \"s2\": {\"width_multipliers\": (1.5, 2.0, 2.5, 4.0)},\n",
        "    \"s3\": {\"width_multipliers\": (2.0, 2.5, 3.0, 4.0)},\n",
        "    \"s4\": {\"width_multipliers\": (3.0, 3.5, 3.5, 4.0),\n",
        "           \"use_se\": True},\n",
        "}\n",
        "\n",
        "\n",
        "def mobileone(num_classes: int = 1000, inference_mode: bool = False,\n",
        "              variant: str = \"s0\") -> nn.Module:\n",
        "    \"\"\"Get MobileOne model.\n",
        "\n",
        "    :param num_classes: Number of classes in the dataset.\n",
        "    :param inference_mode: If True, instantiates model in inference mode.\n",
        "    :param variant: Which type of model to generate.\n",
        "    :return: MobileOne model. \"\"\"\n",
        "    variant_params = PARAMS[variant]\n",
        "    return MobileOne(num_classes=num_classes, inference_mode=inference_mode,\n",
        "                     **variant_params)\n",
        "\n",
        "\n",
        "def reparameterize_model(model: torch.nn.Module) -> nn.Module:\n",
        "    \"\"\" Method returns a model where a multi-branched structure\n",
        "        used in training is re-parameterized into a single branch\n",
        "        for inference.\n",
        "\n",
        "    :param model: MobileOne model in train mode.\n",
        "    :return: MobileOne model in inference mode.\n",
        "    \"\"\"\n",
        "    # Avoid editing original graph\n",
        "    model = copy.deepcopy(model)\n",
        "    for module in model.modules():\n",
        "        if hasattr(module, 'reparameterize'):\n",
        "            module.reparameterize()\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9eba6a6b",
      "metadata": {
        "id": "9eba6a6b",
        "papermill": {
          "duration": 0.015441,
          "end_time": "2024-04-01T21:29:49.362598",
          "exception": false,
          "start_time": "2024-04-01T21:29:49.347157",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "### Reparameterization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00791c9d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-01T21:29:49.396141Z",
          "iopub.status.busy": "2024-04-01T21:29:49.395843Z",
          "iopub.status.idle": "2024-04-01T21:29:58.042082Z",
          "shell.execute_reply": "2024-04-01T21:29:58.040970Z"
        },
        "id": "00791c9d",
        "outputId": "814f1964-02fe-486f-e8fc-c2046d118cf6",
        "papermill": {
          "duration": 8.666097,
          "end_time": "2024-04-01T21:29:58.044538",
          "exception": false,
          "start_time": "2024-04-01T21:29:49.378441",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "drop path: Identity()\n",
            "drop path: DropPath()\n",
            "drop path: DropPath()\n",
            "drop path: DropPath()\n",
            "drop path: DropPath()\n",
            "drop path: DropPath()\n",
            "drop path: DropPath()\n",
            "drop path: DropPath()\n",
            "drop path: DropPath()\n",
            "drop path: DropPath()\n",
            "drop path: DropPath()\n",
            "drop path: DropPath()\n",
            "drop path: DropPath()\n",
            "drop path: DropPath()\n",
            "drop path: DropPath()\n",
            "drop path: DropPath()\n",
            "drop path: DropPath()\n",
            "drop path: DropPath()\n",
            "drop path: DropPath()\n",
            "drop path: DropPath()\n",
            "drop path: DropPath()\n",
            "drop path: DropPath()\n",
            "drop path: DropPath()\n",
            "drop path: DropPath()\n",
            "------------------- training-time model -------------\n",
            "RepLKNet(\n",
            "  (stem): ModuleList(\n",
            "    (0): Sequential(\n",
            "      (conv): Conv2d(3, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (nonlinear): ReLU()\n",
            "    )\n",
            "    (1): Sequential(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
            "      (bn): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (nonlinear): ReLU()\n",
            "    )\n",
            "    (2): Sequential(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (nonlinear): ReLU()\n",
            "    )\n",
            "    (3): Sequential(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n",
            "      (bn): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (nonlinear): ReLU()\n",
            "    )\n",
            "  )\n",
            "  (stages): ModuleList(\n",
            "    (0): RepLKNetStage(\n",
            "      (blocks): ModuleList(\n",
            "        (0): RepLKBlock(\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (nonlinear): ReLU()\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (large_kernel): ReparamLargeKernelConv(\n",
            "            (lkb_origin): Sequential(\n",
            "              (conv): Conv2d(128, 128, kernel_size=(31, 31), stride=(1, 1), padding=(15, 15), groups=128, bias=False)\n",
            "              (bn): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (small_conv): Sequential(\n",
            "              (conv): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128, bias=False)\n",
            "              (bn): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (lk_nonlinear): ReLU()\n",
            "          (prelkb_bn): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (drop_path): Identity()\n",
            "        )\n",
            "        (1): ConvFFN(\n",
            "          (drop_path): Identity()\n",
            "          (preffn_bn): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (nonlinear): GELU(approximate='none')\n",
            "        )\n",
            "        (2): RepLKBlock(\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (nonlinear): ReLU()\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (large_kernel): ReparamLargeKernelConv(\n",
            "            (lkb_origin): Sequential(\n",
            "              (conv): Conv2d(128, 128, kernel_size=(31, 31), stride=(1, 1), padding=(15, 15), groups=128, bias=False)\n",
            "              (bn): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (small_conv): Sequential(\n",
            "              (conv): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128, bias=False)\n",
            "              (bn): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (lk_nonlinear): ReLU()\n",
            "          (prelkb_bn): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (drop_path): DropPath()\n",
            "        )\n",
            "        (3): ConvFFN(\n",
            "          (drop_path): DropPath()\n",
            "          (preffn_bn): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (nonlinear): GELU(approximate='none')\n",
            "        )\n",
            "      )\n",
            "      (norm): Identity()\n",
            "    )\n",
            "    (1): RepLKNetStage(\n",
            "      (blocks): ModuleList(\n",
            "        (0): RepLKBlock(\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (nonlinear): ReLU()\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (large_kernel): ReparamLargeKernelConv(\n",
            "            (lkb_origin): Sequential(\n",
            "              (conv): Conv2d(256, 256, kernel_size=(29, 29), stride=(1, 1), padding=(14, 14), groups=256, bias=False)\n",
            "              (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (small_conv): Sequential(\n",
            "              (conv): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=256, bias=False)\n",
            "              (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (lk_nonlinear): ReLU()\n",
            "          (prelkb_bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (drop_path): DropPath()\n",
            "        )\n",
            "        (1): ConvFFN(\n",
            "          (drop_path): DropPath()\n",
            "          (preffn_bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (nonlinear): GELU(approximate='none')\n",
            "        )\n",
            "        (2): RepLKBlock(\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (nonlinear): ReLU()\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (large_kernel): ReparamLargeKernelConv(\n",
            "            (lkb_origin): Sequential(\n",
            "              (conv): Conv2d(256, 256, kernel_size=(29, 29), stride=(1, 1), padding=(14, 14), groups=256, bias=False)\n",
            "              (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (small_conv): Sequential(\n",
            "              (conv): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=256, bias=False)\n",
            "              (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (lk_nonlinear): ReLU()\n",
            "          (prelkb_bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (drop_path): DropPath()\n",
            "        )\n",
            "        (3): ConvFFN(\n",
            "          (drop_path): DropPath()\n",
            "          (preffn_bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (nonlinear): GELU(approximate='none')\n",
            "        )\n",
            "      )\n",
            "      (norm): Identity()\n",
            "    )\n",
            "    (2): RepLKNetStage(\n",
            "      (blocks): ModuleList(\n",
            "        (0): RepLKBlock(\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (nonlinear): ReLU()\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (large_kernel): ReparamLargeKernelConv(\n",
            "            (lkb_origin): Sequential(\n",
            "              (conv): Conv2d(512, 512, kernel_size=(27, 27), stride=(1, 1), padding=(13, 13), groups=512, bias=False)\n",
            "              (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (small_conv): Sequential(\n",
            "              (conv): Conv2d(512, 512, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=512, bias=False)\n",
            "              (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (lk_nonlinear): ReLU()\n",
            "          (prelkb_bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (drop_path): DropPath()\n",
            "        )\n",
            "        (1): ConvFFN(\n",
            "          (drop_path): DropPath()\n",
            "          (preffn_bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (nonlinear): GELU(approximate='none')\n",
            "        )\n",
            "        (2): RepLKBlock(\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (nonlinear): ReLU()\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (large_kernel): ReparamLargeKernelConv(\n",
            "            (lkb_origin): Sequential(\n",
            "              (conv): Conv2d(512, 512, kernel_size=(27, 27), stride=(1, 1), padding=(13, 13), groups=512, bias=False)\n",
            "              (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (small_conv): Sequential(\n",
            "              (conv): Conv2d(512, 512, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=512, bias=False)\n",
            "              (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (lk_nonlinear): ReLU()\n",
            "          (prelkb_bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (drop_path): DropPath()\n",
            "        )\n",
            "        (3): ConvFFN(\n",
            "          (drop_path): DropPath()\n",
            "          (preffn_bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (nonlinear): GELU(approximate='none')\n",
            "        )\n",
            "        (4): RepLKBlock(\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (nonlinear): ReLU()\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (large_kernel): ReparamLargeKernelConv(\n",
            "            (lkb_origin): Sequential(\n",
            "              (conv): Conv2d(512, 512, kernel_size=(27, 27), stride=(1, 1), padding=(13, 13), groups=512, bias=False)\n",
            "              (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (small_conv): Sequential(\n",
            "              (conv): Conv2d(512, 512, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=512, bias=False)\n",
            "              (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (lk_nonlinear): ReLU()\n",
            "          (prelkb_bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (drop_path): DropPath()\n",
            "        )\n",
            "        (5): ConvFFN(\n",
            "          (drop_path): DropPath()\n",
            "          (preffn_bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (nonlinear): GELU(approximate='none')\n",
            "        )\n",
            "        (6): RepLKBlock(\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (nonlinear): ReLU()\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (large_kernel): ReparamLargeKernelConv(\n",
            "            (lkb_origin): Sequential(\n",
            "              (conv): Conv2d(512, 512, kernel_size=(27, 27), stride=(1, 1), padding=(13, 13), groups=512, bias=False)\n",
            "              (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (small_conv): Sequential(\n",
            "              (conv): Conv2d(512, 512, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=512, bias=False)\n",
            "              (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (lk_nonlinear): ReLU()\n",
            "          (prelkb_bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (drop_path): DropPath()\n",
            "        )\n",
            "        (7): ConvFFN(\n",
            "          (drop_path): DropPath()\n",
            "          (preffn_bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (nonlinear): GELU(approximate='none')\n",
            "        )\n",
            "        (8): RepLKBlock(\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (nonlinear): ReLU()\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (large_kernel): ReparamLargeKernelConv(\n",
            "            (lkb_origin): Sequential(\n",
            "              (conv): Conv2d(512, 512, kernel_size=(27, 27), stride=(1, 1), padding=(13, 13), groups=512, bias=False)\n",
            "              (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (small_conv): Sequential(\n",
            "              (conv): Conv2d(512, 512, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=512, bias=False)\n",
            "              (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (lk_nonlinear): ReLU()\n",
            "          (prelkb_bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (drop_path): DropPath()\n",
            "        )\n",
            "        (9): ConvFFN(\n",
            "          (drop_path): DropPath()\n",
            "          (preffn_bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (nonlinear): GELU(approximate='none')\n",
            "        )\n",
            "        (10): RepLKBlock(\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (nonlinear): ReLU()\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (large_kernel): ReparamLargeKernelConv(\n",
            "            (lkb_origin): Sequential(\n",
            "              (conv): Conv2d(512, 512, kernel_size=(27, 27), stride=(1, 1), padding=(13, 13), groups=512, bias=False)\n",
            "              (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (small_conv): Sequential(\n",
            "              (conv): Conv2d(512, 512, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=512, bias=False)\n",
            "              (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (lk_nonlinear): ReLU()\n",
            "          (prelkb_bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (drop_path): DropPath()\n",
            "        )\n",
            "        (11): ConvFFN(\n",
            "          (drop_path): DropPath()\n",
            "          (preffn_bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (nonlinear): GELU(approximate='none')\n",
            "        )\n",
            "        (12): RepLKBlock(\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (nonlinear): ReLU()\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (large_kernel): ReparamLargeKernelConv(\n",
            "            (lkb_origin): Sequential(\n",
            "              (conv): Conv2d(512, 512, kernel_size=(27, 27), stride=(1, 1), padding=(13, 13), groups=512, bias=False)\n",
            "              (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (small_conv): Sequential(\n",
            "              (conv): Conv2d(512, 512, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=512, bias=False)\n",
            "              (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (lk_nonlinear): ReLU()\n",
            "          (prelkb_bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (drop_path): DropPath()\n",
            "        )\n",
            "        (13): ConvFFN(\n",
            "          (drop_path): DropPath()\n",
            "          (preffn_bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (nonlinear): GELU(approximate='none')\n",
            "        )\n",
            "        (14): RepLKBlock(\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (nonlinear): ReLU()\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (large_kernel): ReparamLargeKernelConv(\n",
            "            (lkb_origin): Sequential(\n",
            "              (conv): Conv2d(512, 512, kernel_size=(27, 27), stride=(1, 1), padding=(13, 13), groups=512, bias=False)\n",
            "              (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (small_conv): Sequential(\n",
            "              (conv): Conv2d(512, 512, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=512, bias=False)\n",
            "              (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (lk_nonlinear): ReLU()\n",
            "          (prelkb_bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (drop_path): DropPath()\n",
            "        )\n",
            "        (15): ConvFFN(\n",
            "          (drop_path): DropPath()\n",
            "          (preffn_bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (nonlinear): GELU(approximate='none')\n",
            "        )\n",
            "        (16): RepLKBlock(\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (nonlinear): ReLU()\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (large_kernel): ReparamLargeKernelConv(\n",
            "            (lkb_origin): Sequential(\n",
            "              (conv): Conv2d(512, 512, kernel_size=(27, 27), stride=(1, 1), padding=(13, 13), groups=512, bias=False)\n",
            "              (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (small_conv): Sequential(\n",
            "              (conv): Conv2d(512, 512, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=512, bias=False)\n",
            "              (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (lk_nonlinear): ReLU()\n",
            "          (prelkb_bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (drop_path): DropPath()\n",
            "        )\n",
            "        (17): ConvFFN(\n",
            "          (drop_path): DropPath()\n",
            "          (preffn_bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (nonlinear): GELU(approximate='none')\n",
            "        )\n",
            "        (18): RepLKBlock(\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (nonlinear): ReLU()\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (large_kernel): ReparamLargeKernelConv(\n",
            "            (lkb_origin): Sequential(\n",
            "              (conv): Conv2d(512, 512, kernel_size=(27, 27), stride=(1, 1), padding=(13, 13), groups=512, bias=False)\n",
            "              (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (small_conv): Sequential(\n",
            "              (conv): Conv2d(512, 512, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=512, bias=False)\n",
            "              (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (lk_nonlinear): ReLU()\n",
            "          (prelkb_bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (drop_path): DropPath()\n",
            "        )\n",
            "        (19): ConvFFN(\n",
            "          (drop_path): DropPath()\n",
            "          (preffn_bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (nonlinear): GELU(approximate='none')\n",
            "        )\n",
            "        (20): RepLKBlock(\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (nonlinear): ReLU()\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (large_kernel): ReparamLargeKernelConv(\n",
            "            (lkb_origin): Sequential(\n",
            "              (conv): Conv2d(512, 512, kernel_size=(27, 27), stride=(1, 1), padding=(13, 13), groups=512, bias=False)\n",
            "              (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (small_conv): Sequential(\n",
            "              (conv): Conv2d(512, 512, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=512, bias=False)\n",
            "              (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (lk_nonlinear): ReLU()\n",
            "          (prelkb_bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (drop_path): DropPath()\n",
            "        )\n",
            "        (21): ConvFFN(\n",
            "          (drop_path): DropPath()\n",
            "          (preffn_bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (nonlinear): GELU(approximate='none')\n",
            "        )\n",
            "        (22): RepLKBlock(\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (nonlinear): ReLU()\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (large_kernel): ReparamLargeKernelConv(\n",
            "            (lkb_origin): Sequential(\n",
            "              (conv): Conv2d(512, 512, kernel_size=(27, 27), stride=(1, 1), padding=(13, 13), groups=512, bias=False)\n",
            "              (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (small_conv): Sequential(\n",
            "              (conv): Conv2d(512, 512, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=512, bias=False)\n",
            "              (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (lk_nonlinear): ReLU()\n",
            "          (prelkb_bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (drop_path): DropPath()\n",
            "        )\n",
            "        (23): ConvFFN(\n",
            "          (drop_path): DropPath()\n",
            "          (preffn_bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (nonlinear): GELU(approximate='none')\n",
            "        )\n",
            "        (24): RepLKBlock(\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (nonlinear): ReLU()\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (large_kernel): ReparamLargeKernelConv(\n",
            "            (lkb_origin): Sequential(\n",
            "              (conv): Conv2d(512, 512, kernel_size=(27, 27), stride=(1, 1), padding=(13, 13), groups=512, bias=False)\n",
            "              (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (small_conv): Sequential(\n",
            "              (conv): Conv2d(512, 512, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=512, bias=False)\n",
            "              (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (lk_nonlinear): ReLU()\n",
            "          (prelkb_bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (drop_path): DropPath()\n",
            "        )\n",
            "        (25): ConvFFN(\n",
            "          (drop_path): DropPath()\n",
            "          (preffn_bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (nonlinear): GELU(approximate='none')\n",
            "        )\n",
            "        (26): RepLKBlock(\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (nonlinear): ReLU()\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (large_kernel): ReparamLargeKernelConv(\n",
            "            (lkb_origin): Sequential(\n",
            "              (conv): Conv2d(512, 512, kernel_size=(27, 27), stride=(1, 1), padding=(13, 13), groups=512, bias=False)\n",
            "              (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (small_conv): Sequential(\n",
            "              (conv): Conv2d(512, 512, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=512, bias=False)\n",
            "              (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (lk_nonlinear): ReLU()\n",
            "          (prelkb_bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (drop_path): DropPath()\n",
            "        )\n",
            "        (27): ConvFFN(\n",
            "          (drop_path): DropPath()\n",
            "          (preffn_bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (nonlinear): GELU(approximate='none')\n",
            "        )\n",
            "        (28): RepLKBlock(\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (nonlinear): ReLU()\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (large_kernel): ReparamLargeKernelConv(\n",
            "            (lkb_origin): Sequential(\n",
            "              (conv): Conv2d(512, 512, kernel_size=(27, 27), stride=(1, 1), padding=(13, 13), groups=512, bias=False)\n",
            "              (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (small_conv): Sequential(\n",
            "              (conv): Conv2d(512, 512, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=512, bias=False)\n",
            "              (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (lk_nonlinear): ReLU()\n",
            "          (prelkb_bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (drop_path): DropPath()\n",
            "        )\n",
            "        (29): ConvFFN(\n",
            "          (drop_path): DropPath()\n",
            "          (preffn_bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (nonlinear): GELU(approximate='none')\n",
            "        )\n",
            "        (30): RepLKBlock(\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (nonlinear): ReLU()\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (large_kernel): ReparamLargeKernelConv(\n",
            "            (lkb_origin): Sequential(\n",
            "              (conv): Conv2d(512, 512, kernel_size=(27, 27), stride=(1, 1), padding=(13, 13), groups=512, bias=False)\n",
            "              (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (small_conv): Sequential(\n",
            "              (conv): Conv2d(512, 512, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=512, bias=False)\n",
            "              (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (lk_nonlinear): ReLU()\n",
            "          (prelkb_bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (drop_path): DropPath()\n",
            "        )\n",
            "        (31): ConvFFN(\n",
            "          (drop_path): DropPath()\n",
            "          (preffn_bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (nonlinear): GELU(approximate='none')\n",
            "        )\n",
            "        (32): RepLKBlock(\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (nonlinear): ReLU()\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (large_kernel): ReparamLargeKernelConv(\n",
            "            (lkb_origin): Sequential(\n",
            "              (conv): Conv2d(512, 512, kernel_size=(27, 27), stride=(1, 1), padding=(13, 13), groups=512, bias=False)\n",
            "              (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (small_conv): Sequential(\n",
            "              (conv): Conv2d(512, 512, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=512, bias=False)\n",
            "              (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (lk_nonlinear): ReLU()\n",
            "          (prelkb_bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (drop_path): DropPath()\n",
            "        )\n",
            "        (33): ConvFFN(\n",
            "          (drop_path): DropPath()\n",
            "          (preffn_bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (nonlinear): GELU(approximate='none')\n",
            "        )\n",
            "        (34): RepLKBlock(\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (nonlinear): ReLU()\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (large_kernel): ReparamLargeKernelConv(\n",
            "            (lkb_origin): Sequential(\n",
            "              (conv): Conv2d(512, 512, kernel_size=(27, 27), stride=(1, 1), padding=(13, 13), groups=512, bias=False)\n",
            "              (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (small_conv): Sequential(\n",
            "              (conv): Conv2d(512, 512, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=512, bias=False)\n",
            "              (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (lk_nonlinear): ReLU()\n",
            "          (prelkb_bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (drop_path): DropPath()\n",
            "        )\n",
            "        (35): ConvFFN(\n",
            "          (drop_path): DropPath()\n",
            "          (preffn_bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (nonlinear): GELU(approximate='none')\n",
            "        )\n",
            "      )\n",
            "      (norm): Identity()\n",
            "    )\n",
            "    (3): RepLKNetStage(\n",
            "      (blocks): ModuleList(\n",
            "        (0): RepLKBlock(\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (nonlinear): ReLU()\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (large_kernel): ReparamLargeKernelConv(\n",
            "            (lkb_origin): Sequential(\n",
            "              (conv): Conv2d(1024, 1024, kernel_size=(13, 13), stride=(1, 1), padding=(6, 6), groups=1024, bias=False)\n",
            "              (bn): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (small_conv): Sequential(\n",
            "              (conv): Conv2d(1024, 1024, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1024, bias=False)\n",
            "              (bn): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (lk_nonlinear): ReLU()\n",
            "          (prelkb_bn): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (drop_path): DropPath()\n",
            "        )\n",
            "        (1): ConvFFN(\n",
            "          (drop_path): DropPath()\n",
            "          (preffn_bn): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(1024, 4096, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(4096, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (nonlinear): GELU(approximate='none')\n",
            "        )\n",
            "        (2): RepLKBlock(\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (nonlinear): ReLU()\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (large_kernel): ReparamLargeKernelConv(\n",
            "            (lkb_origin): Sequential(\n",
            "              (conv): Conv2d(1024, 1024, kernel_size=(13, 13), stride=(1, 1), padding=(6, 6), groups=1024, bias=False)\n",
            "              (bn): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (small_conv): Sequential(\n",
            "              (conv): Conv2d(1024, 1024, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1024, bias=False)\n",
            "              (bn): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (lk_nonlinear): ReLU()\n",
            "          (prelkb_bn): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (drop_path): DropPath()\n",
            "        )\n",
            "        (3): ConvFFN(\n",
            "          (drop_path): DropPath()\n",
            "          (preffn_bn): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(1024, 4096, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(4096, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (nonlinear): GELU(approximate='none')\n",
            "        )\n",
            "      )\n",
            "      (norm): Identity()\n",
            "    )\n",
            "  )\n",
            "  (transitions): ModuleList(\n",
            "    (0): Sequential(\n",
            "      (0): Sequential(\n",
            "        (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (nonlinear): ReLU()\n",
            "      )\n",
            "      (1): Sequential(\n",
            "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)\n",
            "        (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (nonlinear): ReLU()\n",
            "      )\n",
            "    )\n",
            "    (1): Sequential(\n",
            "      (0): Sequential(\n",
            "        (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (nonlinear): ReLU()\n",
            "      )\n",
            "      (1): Sequential(\n",
            "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512, bias=False)\n",
            "        (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (nonlinear): ReLU()\n",
            "      )\n",
            "    )\n",
            "    (2): Sequential(\n",
            "      (0): Sequential(\n",
            "        (conv): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (nonlinear): ReLU()\n",
            "      )\n",
            "      (1): Sequential(\n",
            "        (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=1024, bias=False)\n",
            "        (bn): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (nonlinear): ReLU()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "  (head): Linear(in_features=1024, out_features=1000, bias=True)\n",
            ")\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------------------- after re-param -------------\n",
            "RepLKNet(\n",
            "  (stem): ModuleList(\n",
            "    (0): Sequential(\n",
            "      (conv): Conv2d(3, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (nonlinear): ReLU()\n",
            "    )\n",
            "    (1): Sequential(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
            "      (bn): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (nonlinear): ReLU()\n",
            "    )\n",
            "    (2): Sequential(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (nonlinear): ReLU()\n",
            "    )\n",
            "    (3): Sequential(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n",
            "      (bn): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (nonlinear): ReLU()\n",
            "    )\n",
            "  )\n",
            "  (stages): ModuleList(\n",
            "    (0): RepLKNetStage(\n",
            "      (blocks): ModuleList(\n",
            "        (0): RepLKBlock(\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (nonlinear): ReLU()\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (large_kernel): ReparamLargeKernelConv(\n",
            "            (lkb_reparam): Conv2d(128, 128, kernel_size=(31, 31), stride=(1, 1), padding=(15, 15), groups=128)\n",
            "          )\n",
            "          (lk_nonlinear): ReLU()\n",
            "          (prelkb_bn): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (drop_path): Identity()\n",
            "        )\n",
            "        (1): ConvFFN(\n",
            "          (drop_path): Identity()\n",
            "          (preffn_bn): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (nonlinear): GELU(approximate='none')\n",
            "        )\n",
            "        (2): RepLKBlock(\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (nonlinear): ReLU()\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (large_kernel): ReparamLargeKernelConv(\n",
            "            (lkb_reparam): Conv2d(128, 128, kernel_size=(31, 31), stride=(1, 1), padding=(15, 15), groups=128)\n",
            "          )\n",
            "          (lk_nonlinear): ReLU()\n",
            "          (prelkb_bn): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (drop_path): DropPath()\n",
            "        )\n",
            "        (3): ConvFFN(\n",
            "          (drop_path): DropPath()\n",
            "          (preffn_bn): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (nonlinear): GELU(approximate='none')\n",
            "        )\n",
            "      )\n",
            "      (norm): Identity()\n",
            "    )\n",
            "    (1): RepLKNetStage(\n",
            "      (blocks): ModuleList(\n",
            "        (0): RepLKBlock(\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (nonlinear): ReLU()\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (large_kernel): ReparamLargeKernelConv(\n",
            "            (lkb_reparam): Conv2d(256, 256, kernel_size=(29, 29), stride=(1, 1), padding=(14, 14), groups=256)\n",
            "          )\n",
            "          (lk_nonlinear): ReLU()\n",
            "          (prelkb_bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (drop_path): DropPath()\n",
            "        )\n",
            "        (1): ConvFFN(\n",
            "          (drop_path): DropPath()\n",
            "          (preffn_bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (nonlinear): GELU(approximate='none')\n",
            "        )\n",
            "        (2): RepLKBlock(\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (nonlinear): ReLU()\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (large_kernel): ReparamLargeKernelConv(\n",
            "            (lkb_reparam): Conv2d(256, 256, kernel_size=(29, 29), stride=(1, 1), padding=(14, 14), groups=256)\n",
            "          )\n",
            "          (lk_nonlinear): ReLU()\n",
            "          (prelkb_bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (drop_path): DropPath()\n",
            "        )\n",
            "        (3): ConvFFN(\n",
            "          (drop_path): DropPath()\n",
            "          (preffn_bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (nonlinear): GELU(approximate='none')\n",
            "        )\n",
            "      )\n",
            "      (norm): Identity()\n",
            "    )\n",
            "    (2): RepLKNetStage(\n",
            "      (blocks): ModuleList(\n",
            "        (0): RepLKBlock(\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (nonlinear): ReLU()\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (large_kernel): ReparamLargeKernelConv(\n",
            "            (lkb_reparam): Conv2d(512, 512, kernel_size=(27, 27), stride=(1, 1), padding=(13, 13), groups=512)\n",
            "          )\n",
            "          (lk_nonlinear): ReLU()\n",
            "          (prelkb_bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (drop_path): DropPath()\n",
            "        )\n",
            "        (1): ConvFFN(\n",
            "          (drop_path): DropPath()\n",
            "          (preffn_bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (nonlinear): GELU(approximate='none')\n",
            "        )\n",
            "        (2): RepLKBlock(\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (nonlinear): ReLU()\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (large_kernel): ReparamLargeKernelConv(\n",
            "            (lkb_reparam): Conv2d(512, 512, kernel_size=(27, 27), stride=(1, 1), padding=(13, 13), groups=512)\n",
            "          )\n",
            "          (lk_nonlinear): ReLU()\n",
            "          (prelkb_bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (drop_path): DropPath()\n",
            "        )\n",
            "        (3): ConvFFN(\n",
            "          (drop_path): DropPath()\n",
            "          (preffn_bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (nonlinear): GELU(approximate='none')\n",
            "        )\n",
            "        (4): RepLKBlock(\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (nonlinear): ReLU()\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (large_kernel): ReparamLargeKernelConv(\n",
            "            (lkb_reparam): Conv2d(512, 512, kernel_size=(27, 27), stride=(1, 1), padding=(13, 13), groups=512)\n",
            "          )\n",
            "          (lk_nonlinear): ReLU()\n",
            "          (prelkb_bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (drop_path): DropPath()\n",
            "        )\n",
            "        (5): ConvFFN(\n",
            "          (drop_path): DropPath()\n",
            "          (preffn_bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (nonlinear): GELU(approximate='none')\n",
            "        )\n",
            "        (6): RepLKBlock(\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (nonlinear): ReLU()\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (large_kernel): ReparamLargeKernelConv(\n",
            "            (lkb_reparam): Conv2d(512, 512, kernel_size=(27, 27), stride=(1, 1), padding=(13, 13), groups=512)\n",
            "          )\n",
            "          (lk_nonlinear): ReLU()\n",
            "          (prelkb_bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (drop_path): DropPath()\n",
            "        )\n",
            "        (7): ConvFFN(\n",
            "          (drop_path): DropPath()\n",
            "          (preffn_bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (nonlinear): GELU(approximate='none')\n",
            "        )\n",
            "        (8): RepLKBlock(\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (nonlinear): ReLU()\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (large_kernel): ReparamLargeKernelConv(\n",
            "            (lkb_reparam): Conv2d(512, 512, kernel_size=(27, 27), stride=(1, 1), padding=(13, 13), groups=512)\n",
            "          )\n",
            "          (lk_nonlinear): ReLU()\n",
            "          (prelkb_bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (drop_path): DropPath()\n",
            "        )\n",
            "        (9): ConvFFN(\n",
            "          (drop_path): DropPath()\n",
            "          (preffn_bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (nonlinear): GELU(approximate='none')\n",
            "        )\n",
            "        (10): RepLKBlock(\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (nonlinear): ReLU()\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (large_kernel): ReparamLargeKernelConv(\n",
            "            (lkb_reparam): Conv2d(512, 512, kernel_size=(27, 27), stride=(1, 1), padding=(13, 13), groups=512)\n",
            "          )\n",
            "          (lk_nonlinear): ReLU()\n",
            "          (prelkb_bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (drop_path): DropPath()\n",
            "        )\n",
            "        (11): ConvFFN(\n",
            "          (drop_path): DropPath()\n",
            "          (preffn_bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (nonlinear): GELU(approximate='none')\n",
            "        )\n",
            "        (12): RepLKBlock(\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (nonlinear): ReLU()\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (large_kernel): ReparamLargeKernelConv(\n",
            "            (lkb_reparam): Conv2d(512, 512, kernel_size=(27, 27), stride=(1, 1), padding=(13, 13), groups=512)\n",
            "          )\n",
            "          (lk_nonlinear): ReLU()\n",
            "          (prelkb_bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (drop_path): DropPath()\n",
            "        )\n",
            "        (13): ConvFFN(\n",
            "          (drop_path): DropPath()\n",
            "          (preffn_bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (nonlinear): GELU(approximate='none')\n",
            "        )\n",
            "        (14): RepLKBlock(\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (nonlinear): ReLU()\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (large_kernel): ReparamLargeKernelConv(\n",
            "            (lkb_reparam): Conv2d(512, 512, kernel_size=(27, 27), stride=(1, 1), padding=(13, 13), groups=512)\n",
            "          )\n",
            "          (lk_nonlinear): ReLU()\n",
            "          (prelkb_bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (drop_path): DropPath()\n",
            "        )\n",
            "        (15): ConvFFN(\n",
            "          (drop_path): DropPath()\n",
            "          (preffn_bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (nonlinear): GELU(approximate='none')\n",
            "        )\n",
            "        (16): RepLKBlock(\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (nonlinear): ReLU()\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (large_kernel): ReparamLargeKernelConv(\n",
            "            (lkb_reparam): Conv2d(512, 512, kernel_size=(27, 27), stride=(1, 1), padding=(13, 13), groups=512)\n",
            "          )\n",
            "          (lk_nonlinear): ReLU()\n",
            "          (prelkb_bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (drop_path): DropPath()\n",
            "        )\n",
            "        (17): ConvFFN(\n",
            "          (drop_path): DropPath()\n",
            "          (preffn_bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (nonlinear): GELU(approximate='none')\n",
            "        )\n",
            "        (18): RepLKBlock(\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (nonlinear): ReLU()\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (large_kernel): ReparamLargeKernelConv(\n",
            "            (lkb_reparam): Conv2d(512, 512, kernel_size=(27, 27), stride=(1, 1), padding=(13, 13), groups=512)\n",
            "          )\n",
            "          (lk_nonlinear): ReLU()\n",
            "          (prelkb_bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (drop_path): DropPath()\n",
            "        )\n",
            "        (19): ConvFFN(\n",
            "          (drop_path): DropPath()\n",
            "          (preffn_bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (nonlinear): GELU(approximate='none')\n",
            "        )\n",
            "        (20): RepLKBlock(\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (nonlinear): ReLU()\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (large_kernel): ReparamLargeKernelConv(\n",
            "            (lkb_reparam): Conv2d(512, 512, kernel_size=(27, 27), stride=(1, 1), padding=(13, 13), groups=512)\n",
            "          )\n",
            "          (lk_nonlinear): ReLU()\n",
            "          (prelkb_bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (drop_path): DropPath()\n",
            "        )\n",
            "        (21): ConvFFN(\n",
            "          (drop_path): DropPath()\n",
            "          (preffn_bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (nonlinear): GELU(approximate='none')\n",
            "        )\n",
            "        (22): RepLKBlock(\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (nonlinear): ReLU()\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (large_kernel): ReparamLargeKernelConv(\n",
            "            (lkb_reparam): Conv2d(512, 512, kernel_size=(27, 27), stride=(1, 1), padding=(13, 13), groups=512)\n",
            "          )\n",
            "          (lk_nonlinear): ReLU()\n",
            "          (prelkb_bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (drop_path): DropPath()\n",
            "        )\n",
            "        (23): ConvFFN(\n",
            "          (drop_path): DropPath()\n",
            "          (preffn_bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (nonlinear): GELU(approximate='none')\n",
            "        )\n",
            "        (24): RepLKBlock(\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (nonlinear): ReLU()\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (large_kernel): ReparamLargeKernelConv(\n",
            "            (lkb_reparam): Conv2d(512, 512, kernel_size=(27, 27), stride=(1, 1), padding=(13, 13), groups=512)\n",
            "          )\n",
            "          (lk_nonlinear): ReLU()\n",
            "          (prelkb_bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (drop_path): DropPath()\n",
            "        )\n",
            "        (25): ConvFFN(\n",
            "          (drop_path): DropPath()\n",
            "          (preffn_bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (nonlinear): GELU(approximate='none')\n",
            "        )\n",
            "        (26): RepLKBlock(\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (nonlinear): ReLU()\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (large_kernel): ReparamLargeKernelConv(\n",
            "            (lkb_reparam): Conv2d(512, 512, kernel_size=(27, 27), stride=(1, 1), padding=(13, 13), groups=512)\n",
            "          )\n",
            "          (lk_nonlinear): ReLU()\n",
            "          (prelkb_bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (drop_path): DropPath()\n",
            "        )\n",
            "        (27): ConvFFN(\n",
            "          (drop_path): DropPath()\n",
            "          (preffn_bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (nonlinear): GELU(approximate='none')\n",
            "        )\n",
            "        (28): RepLKBlock(\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (nonlinear): ReLU()\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (large_kernel): ReparamLargeKernelConv(\n",
            "            (lkb_reparam): Conv2d(512, 512, kernel_size=(27, 27), stride=(1, 1), padding=(13, 13), groups=512)\n",
            "          )\n",
            "          (lk_nonlinear): ReLU()\n",
            "          (prelkb_bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (drop_path): DropPath()\n",
            "        )\n",
            "        (29): ConvFFN(\n",
            "          (drop_path): DropPath()\n",
            "          (preffn_bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (nonlinear): GELU(approximate='none')\n",
            "        )\n",
            "        (30): RepLKBlock(\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (nonlinear): ReLU()\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (large_kernel): ReparamLargeKernelConv(\n",
            "            (lkb_reparam): Conv2d(512, 512, kernel_size=(27, 27), stride=(1, 1), padding=(13, 13), groups=512)\n",
            "          )\n",
            "          (lk_nonlinear): ReLU()\n",
            "          (prelkb_bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (drop_path): DropPath()\n",
            "        )\n",
            "        (31): ConvFFN(\n",
            "          (drop_path): DropPath()\n",
            "          (preffn_bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (nonlinear): GELU(approximate='none')\n",
            "        )\n",
            "        (32): RepLKBlock(\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (nonlinear): ReLU()\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (large_kernel): ReparamLargeKernelConv(\n",
            "            (lkb_reparam): Conv2d(512, 512, kernel_size=(27, 27), stride=(1, 1), padding=(13, 13), groups=512)\n",
            "          )\n",
            "          (lk_nonlinear): ReLU()\n",
            "          (prelkb_bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (drop_path): DropPath()\n",
            "        )\n",
            "        (33): ConvFFN(\n",
            "          (drop_path): DropPath()\n",
            "          (preffn_bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (nonlinear): GELU(approximate='none')\n",
            "        )\n",
            "        (34): RepLKBlock(\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (nonlinear): ReLU()\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (large_kernel): ReparamLargeKernelConv(\n",
            "            (lkb_reparam): Conv2d(512, 512, kernel_size=(27, 27), stride=(1, 1), padding=(13, 13), groups=512)\n",
            "          )\n",
            "          (lk_nonlinear): ReLU()\n",
            "          (prelkb_bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (drop_path): DropPath()\n",
            "        )\n",
            "        (35): ConvFFN(\n",
            "          (drop_path): DropPath()\n",
            "          (preffn_bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (nonlinear): GELU(approximate='none')\n",
            "        )\n",
            "      )\n",
            "      (norm): Identity()\n",
            "    )\n",
            "    (3): RepLKNetStage(\n",
            "      (blocks): ModuleList(\n",
            "        (0): RepLKBlock(\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (nonlinear): ReLU()\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (large_kernel): ReparamLargeKernelConv(\n",
            "            (lkb_reparam): Conv2d(1024, 1024, kernel_size=(13, 13), stride=(1, 1), padding=(6, 6), groups=1024)\n",
            "          )\n",
            "          (lk_nonlinear): ReLU()\n",
            "          (prelkb_bn): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (drop_path): DropPath()\n",
            "        )\n",
            "        (1): ConvFFN(\n",
            "          (drop_path): DropPath()\n",
            "          (preffn_bn): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(1024, 4096, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(4096, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (nonlinear): GELU(approximate='none')\n",
            "        )\n",
            "        (2): RepLKBlock(\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (nonlinear): ReLU()\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (large_kernel): ReparamLargeKernelConv(\n",
            "            (lkb_reparam): Conv2d(1024, 1024, kernel_size=(13, 13), stride=(1, 1), padding=(6, 6), groups=1024)\n",
            "          )\n",
            "          (lk_nonlinear): ReLU()\n",
            "          (prelkb_bn): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (drop_path): DropPath()\n",
            "        )\n",
            "        (3): ConvFFN(\n",
            "          (drop_path): DropPath()\n",
            "          (preffn_bn): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (pw1): Sequential(\n",
            "            (conv): Conv2d(1024, 4096, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (pw2): Sequential(\n",
            "            (conv): Conv2d(4096, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (nonlinear): GELU(approximate='none')\n",
            "        )\n",
            "      )\n",
            "      (norm): Identity()\n",
            "    )\n",
            "  )\n",
            "  (transitions): ModuleList(\n",
            "    (0): Sequential(\n",
            "      (0): Sequential(\n",
            "        (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (nonlinear): ReLU()\n",
            "      )\n",
            "      (1): Sequential(\n",
            "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)\n",
            "        (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (nonlinear): ReLU()\n",
            "      )\n",
            "    )\n",
            "    (1): Sequential(\n",
            "      (0): Sequential(\n",
            "        (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (nonlinear): ReLU()\n",
            "      )\n",
            "      (1): Sequential(\n",
            "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512, bias=False)\n",
            "        (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (nonlinear): ReLU()\n",
            "      )\n",
            "    )\n",
            "    (2): Sequential(\n",
            "      (0): Sequential(\n",
            "        (conv): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (nonlinear): ReLU()\n",
            "      )\n",
            "      (1): Sequential(\n",
            "        (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=1024, bias=False)\n",
            "        (bn): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (nonlinear): ReLU()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "  (head): Linear(in_features=1024, out_features=1000, bias=True)\n",
            ")\n",
            "------------------- the difference is ------------------------\n",
            "tensor(3.7846e-08, grad_fn=<SumBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# Scaling Up Your Kernels to 31x31: Revisiting Large Kernel Design in CNNs (https://arxiv.org/abs/2203.06717)\n",
        "# Github source: https://github.com/DingXiaoH/RepLKNet-pytorch\n",
        "# Licensed under The MIT License [see LICENSE for details]\n",
        "# Based on ConvNeXt, timm, DINO and DeiT code bases\n",
        "# https://github.com/facebookresearch/ConvNeXt\n",
        "# https://github.com/rwightman/pytorch-image-models/tree/master/timm\n",
        "# https://github.com/facebookresearch/deit/\n",
        "# https://github.com/facebookresearch/dino\n",
        "# --------------------------------------------------------'\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.checkpoint as checkpoint\n",
        "#import DropPath\n",
        "import sys\n",
        "import os\n",
        "\n",
        "def get_conv2d(in_channels, out_channels, kernel_size, stride, padding, dilation, groups, bias):\n",
        "    if type(kernel_size) is int:\n",
        "        use_large_impl = kernel_size > 5\n",
        "    else:\n",
        "        assert len(kernel_size) == 2 and kernel_size[0] == kernel_size[1]\n",
        "        use_large_impl = kernel_size[0] > 5\n",
        "    has_large_impl = 'LARGE_KERNEL_CONV_IMPL' in os.environ\n",
        "    if has_large_impl and in_channels == out_channels and out_channels == groups and use_large_impl and stride == 1 and padding == kernel_size // 2 and dilation == 1:\n",
        "        sys.path.append(os.environ['LARGE_KERNEL_CONV_IMPL'])\n",
        "        #   Please follow the instructions https://github.com/DingXiaoH/RepLKNet-pytorch/blob/main/README.md\n",
        "        #   export LARGE_KERNEL_CONV_IMPL=absolute_path_to_where_you_cloned_the_example (i.e., depthwise_conv2d_implicit_gemm.py)\n",
        "        # TODO more efficient PyTorch implementations of large-kernel convolutions. Pull requests are welcomed.\n",
        "        # Or you may try MegEngine. We have integrated an efficient implementation into MegEngine and it will automatically use it.\n",
        "        from depthwise_conv2d_implicit_gemm import DepthWiseConv2dImplicitGEMM\n",
        "        return DepthWiseConv2dImplicitGEMM(in_channels, kernel_size, bias=bias)\n",
        "    else:\n",
        "        return nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride,\n",
        "                         padding=padding, dilation=dilation, groups=groups, bias=bias)\n",
        "\n",
        "use_sync_bn = False\n",
        "\n",
        "def enable_sync_bn():\n",
        "    global use_sync_bn\n",
        "    use_sync_bn = True\n",
        "\n",
        "def get_bn(channels):\n",
        "    if use_sync_bn:\n",
        "        return nn.SyncBatchNorm(channels)\n",
        "    else:\n",
        "        return nn.BatchNorm2d(channels)\n",
        "\n",
        "def conv_bn(in_channels, out_channels, kernel_size, stride, padding, groups, dilation=1):\n",
        "    if padding is None:\n",
        "        padding = kernel_size // 2\n",
        "    result = nn.Sequential()\n",
        "    result.add_module('conv', get_conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size,\n",
        "                                         stride=stride, padding=padding, dilation=dilation, groups=groups, bias=False))\n",
        "    result.add_module('bn', get_bn(out_channels))\n",
        "    return result\n",
        "\n",
        "def conv_bn_relu(in_channels, out_channels, kernel_size, stride, padding, groups, dilation=1):\n",
        "    if padding is None:\n",
        "        padding = kernel_size // 2\n",
        "    result = conv_bn(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size,\n",
        "                                         stride=stride, padding=padding, groups=groups, dilation=dilation)\n",
        "    result.add_module('nonlinear', nn.ReLU())\n",
        "    return result\n",
        "\n",
        "def fuse_bn(conv, bn):\n",
        "    kernel = conv.weight\n",
        "    running_mean = bn.running_mean\n",
        "    running_var = bn.running_var\n",
        "    gamma = bn.weight\n",
        "    beta = bn.bias\n",
        "    eps = bn.eps\n",
        "    std = (running_var + eps).sqrt()\n",
        "    t = (gamma / std).reshape(-1, 1, 1, 1)\n",
        "    return kernel * t, beta - running_mean * gamma / std\n",
        "\n",
        "class ReparamLargeKernelConv(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, kernel_size,\n",
        "                 stride, groups,\n",
        "                 small_kernel,\n",
        "                 small_kernel_merged=False):\n",
        "        super(ReparamLargeKernelConv, self).__init__()\n",
        "        self.kernel_size = kernel_size\n",
        "        self.small_kernel = small_kernel\n",
        "        # We assume the conv does not change the feature map size, so padding = k//2. Otherwise, you may configure padding as you wish, and change the padding of small_conv accordingly.\n",
        "        padding = kernel_size // 2\n",
        "        if small_kernel_merged:\n",
        "            self.lkb_reparam = get_conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size,\n",
        "                                          stride=stride, padding=padding, dilation=1, groups=groups, bias=True)\n",
        "        else:\n",
        "            self.lkb_origin = conv_bn(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size,\n",
        "                                      stride=stride, padding=padding, dilation=1, groups=groups)\n",
        "            if small_kernel is not None:\n",
        "                assert small_kernel <= kernel_size, 'The kernel size for re-param cannot be larger than the large kernel!'\n",
        "                self.small_conv = conv_bn(in_channels=in_channels, out_channels=out_channels, kernel_size=small_kernel,\n",
        "                                             stride=stride, padding=small_kernel//2, groups=groups, dilation=1)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        if hasattr(self, 'lkb_reparam'):\n",
        "            out = self.lkb_reparam(inputs)\n",
        "        else:\n",
        "            out = self.lkb_origin(inputs)\n",
        "            if hasattr(self, 'small_conv'):\n",
        "                out += self.small_conv(inputs)\n",
        "        return out\n",
        "\n",
        "    def get_equivalent_kernel_bias(self):\n",
        "        eq_k, eq_b = fuse_bn(self.lkb_origin.conv, self.lkb_origin.bn)\n",
        "        if hasattr(self, 'small_conv'):\n",
        "            small_k, small_b = fuse_bn(self.small_conv.conv, self.small_conv.bn)\n",
        "            eq_b += small_b\n",
        "            #   add to the central part\n",
        "            eq_k += nn.functional.pad(small_k, [(self.kernel_size - self.small_kernel) // 2] * 4)\n",
        "        return eq_k, eq_b\n",
        "\n",
        "    def merge_kernel(self):\n",
        "        eq_k, eq_b = self.get_equivalent_kernel_bias()\n",
        "        self.lkb_reparam = get_conv2d(in_channels=self.lkb_origin.conv.in_channels,\n",
        "                                     out_channels=self.lkb_origin.conv.out_channels,\n",
        "                                     kernel_size=self.lkb_origin.conv.kernel_size, stride=self.lkb_origin.conv.stride,\n",
        "                                     padding=self.lkb_origin.conv.padding, dilation=self.lkb_origin.conv.dilation,\n",
        "                                     groups=self.lkb_origin.conv.groups, bias=True)\n",
        "        self.lkb_reparam.weight.data = eq_k\n",
        "        self.lkb_reparam.bias.data = eq_b\n",
        "        self.__delattr__('lkb_origin')\n",
        "        if hasattr(self, 'small_conv'):\n",
        "            self.__delattr__('small_conv')\n",
        "\n",
        "\n",
        "class ConvFFN(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, internal_channels, out_channels, drop_path):\n",
        "        super().__init__()\n",
        "        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
        "        self.preffn_bn = get_bn(in_channels)\n",
        "        self.pw1 = conv_bn(in_channels=in_channels, out_channels=internal_channels, kernel_size=1, stride=1, padding=0, groups=1)\n",
        "        self.pw2 = conv_bn(in_channels=internal_channels, out_channels=out_channels, kernel_size=1, stride=1, padding=0, groups=1)\n",
        "        self.nonlinear = nn.GELU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.preffn_bn(x)\n",
        "        out = self.pw1(out)\n",
        "        out = self.nonlinear(out)\n",
        "        out = self.pw2(out)\n",
        "        return x + self.drop_path(out)\n",
        "\n",
        "\n",
        "class RepLKBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, dw_channels, block_lk_size, small_kernel, drop_path, small_kernel_merged=False):\n",
        "        super().__init__()\n",
        "        self.pw1 = conv_bn_relu(in_channels, dw_channels, 1, 1, 0, groups=1)\n",
        "        self.pw2 = conv_bn(dw_channels, in_channels, 1, 1, 0, groups=1)\n",
        "        self.large_kernel = ReparamLargeKernelConv(in_channels=dw_channels, out_channels=dw_channels, kernel_size=block_lk_size,\n",
        "                                                  stride=1, groups=dw_channels, small_kernel=small_kernel, small_kernel_merged=small_kernel_merged)\n",
        "        self.lk_nonlinear = nn.ReLU()\n",
        "        self.prelkb_bn = get_bn(in_channels)\n",
        "        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
        "        print('drop path:', self.drop_path)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.prelkb_bn(x)\n",
        "        out = self.pw1(out)\n",
        "        out = self.large_kernel(out)\n",
        "        out = self.lk_nonlinear(out)\n",
        "        out = self.pw2(out)\n",
        "        return x + self.drop_path(out)\n",
        "\n",
        "\n",
        "class RepLKNetStage(nn.Module):\n",
        "\n",
        "    def __init__(self, channels, num_blocks, stage_lk_size, drop_path,\n",
        "                 small_kernel, dw_ratio=1, ffn_ratio=4,\n",
        "                 use_checkpoint=False,      # train with torch.utils.checkpoint to save memory\n",
        "                 small_kernel_merged=False,\n",
        "                 norm_intermediate_features=False):\n",
        "        super().__init__()\n",
        "        self.use_checkpoint = use_checkpoint\n",
        "        blks = []\n",
        "        for i in range(num_blocks):\n",
        "            block_drop_path = drop_path[i] if isinstance(drop_path, list) else drop_path\n",
        "            #   Assume all RepLK Blocks within a stage share the same lk_size. You may tune it on your own model.\n",
        "            replk_block = RepLKBlock(in_channels=channels, dw_channels=int(channels * dw_ratio), block_lk_size=stage_lk_size,\n",
        "                                     small_kernel=small_kernel, drop_path=block_drop_path, small_kernel_merged=small_kernel_merged)\n",
        "            convffn_block = ConvFFN(in_channels=channels, internal_channels=int(channels * ffn_ratio), out_channels=channels,\n",
        "                                    drop_path=block_drop_path)\n",
        "            blks.append(replk_block)\n",
        "            blks.append(convffn_block)\n",
        "        self.blocks = nn.ModuleList(blks)\n",
        "        if norm_intermediate_features:\n",
        "            self.norm = get_bn(channels)    #   Only use this with RepLKNet-XL on downstream tasks\n",
        "        else:\n",
        "            self.norm = nn.Identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        for blk in self.blocks:\n",
        "            if self.use_checkpoint:\n",
        "                x = checkpoint.checkpoint(blk, x)   # Save training memory\n",
        "            else:\n",
        "                x = blk(x)\n",
        "        return x\n",
        "\n",
        "class RepLKNet(nn.Module):\n",
        "\n",
        "    def __init__(self, large_kernel_sizes, layers, channels, drop_path_rate, small_kernel,\n",
        "                 dw_ratio=1, ffn_ratio=4, in_channels=3, num_classes=1000, out_indices=None,\n",
        "                 use_checkpoint=False,\n",
        "                 small_kernel_merged=False,\n",
        "                 use_sync_bn=True,\n",
        "                 norm_intermediate_features=False       # for RepLKNet-XL on COCO and ADE20K, use an extra BN to normalize the intermediate feature maps then feed them into the heads\n",
        "                 ):\n",
        "        super().__init__()\n",
        "\n",
        "        if num_classes is None and out_indices is None:\n",
        "            raise ValueError('must specify one of num_classes (for pretraining) and out_indices (for downstream tasks)')\n",
        "        elif num_classes is not None and out_indices is not None:\n",
        "            raise ValueError('cannot specify both num_classes (for pretraining) and out_indices (for downstream tasks)')\n",
        "        elif num_classes is not None and norm_intermediate_features:\n",
        "            raise ValueError('for pretraining, no need to normalize the intermediate feature maps')\n",
        "        self.out_indices = out_indices\n",
        "        if use_sync_bn:\n",
        "            enable_sync_bn()\n",
        "\n",
        "        base_width = channels[0]\n",
        "        self.use_checkpoint = use_checkpoint\n",
        "        self.norm_intermediate_features = norm_intermediate_features\n",
        "        self.num_stages = len(layers)\n",
        "        self.stem = nn.ModuleList([\n",
        "            conv_bn_relu(in_channels=in_channels, out_channels=base_width, kernel_size=3, stride=2, padding=1, groups=1),\n",
        "            conv_bn_relu(in_channels=base_width, out_channels=base_width, kernel_size=3, stride=1, padding=1, groups=base_width),\n",
        "            conv_bn_relu(in_channels=base_width, out_channels=base_width, kernel_size=1, stride=1, padding=0, groups=1),\n",
        "            conv_bn_relu(in_channels=base_width, out_channels=base_width, kernel_size=3, stride=2, padding=1, groups=base_width)])\n",
        "        # stochastic depth. We set block-wise drop-path rate. The higher level blocks are more likely to be dropped. This implementation follows Swin.\n",
        "        dpr = [x.item() for x in torch.linspace(0, drop_path_rate, sum(layers))]\n",
        "        self.stages = nn.ModuleList()\n",
        "        self.transitions = nn.ModuleList()\n",
        "        for stage_idx in range(self.num_stages):\n",
        "            layer = RepLKNetStage(channels=channels[stage_idx], num_blocks=layers[stage_idx],\n",
        "                                  stage_lk_size=large_kernel_sizes[stage_idx],\n",
        "                                  drop_path=dpr[sum(layers[:stage_idx]):sum(layers[:stage_idx + 1])],\n",
        "                                  small_kernel=small_kernel, dw_ratio=dw_ratio, ffn_ratio=ffn_ratio,\n",
        "                                  use_checkpoint=use_checkpoint, small_kernel_merged=small_kernel_merged,\n",
        "                                  norm_intermediate_features=norm_intermediate_features)\n",
        "            self.stages.append(layer)\n",
        "            if stage_idx < len(layers) - 1:\n",
        "                transition = nn.Sequential(\n",
        "                    conv_bn_relu(channels[stage_idx], channels[stage_idx + 1], 1, 1, 0, groups=1),\n",
        "                    conv_bn_relu(channels[stage_idx + 1], channels[stage_idx + 1], 3, stride=2, padding=1, groups=channels[stage_idx + 1]))\n",
        "                self.transitions.append(transition)\n",
        "\n",
        "        if num_classes is not None:\n",
        "            self.norm = get_bn(channels[-1])\n",
        "            self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
        "            self.head = nn.Linear(channels[-1], num_classes)\n",
        "\n",
        "\n",
        "\n",
        "    def forward_features(self, x):\n",
        "        x = self.stem[0](x)\n",
        "        for stem_layer in self.stem[1:]:\n",
        "            if self.use_checkpoint:\n",
        "                x = checkpoint.checkpoint(stem_layer, x)     # save memory\n",
        "            else:\n",
        "                x = stem_layer(x)\n",
        "\n",
        "        if self.out_indices is None:\n",
        "            #   Just need the final output\n",
        "            for stage_idx in range(self.num_stages):\n",
        "                x = self.stages[stage_idx](x)\n",
        "                if stage_idx < self.num_stages - 1:\n",
        "                    x = self.transitions[stage_idx](x)\n",
        "            return x\n",
        "        else:\n",
        "            #   Need the intermediate feature maps\n",
        "            outs = []\n",
        "            for stage_idx in range(self.num_stages):\n",
        "                x = self.stages[stage_idx](x)\n",
        "                if stage_idx in self.out_indices:\n",
        "                    outs.append(self.stages[stage_idx].norm(x))     # For RepLKNet-XL normalize the features before feeding them into the heads\n",
        "                if stage_idx < self.num_stages - 1:\n",
        "                    x = self.transitions[stage_idx](x)\n",
        "            return outs\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.forward_features(x)\n",
        "        if self.out_indices:\n",
        "            return x\n",
        "        else:\n",
        "            x = self.norm(x)\n",
        "            x = self.avgpool(x)\n",
        "            x = torch.flatten(x, 1)\n",
        "            x = self.head(x)\n",
        "            return x\n",
        "\n",
        "    def structural_reparam(self):\n",
        "        for m in self.modules():\n",
        "            if hasattr(m, 'merge_kernel'):\n",
        "                m.merge_kernel()\n",
        "\n",
        "    #   If your framework cannot automatically fuse BN for inference, you may do it manually.\n",
        "    #   The BNs after and before conv layers can be removed.\n",
        "    #   No need to call this if your framework support automatic BN fusion.\n",
        "    def deep_fuse_BN(self):\n",
        "        for m in self.modules():\n",
        "            if not isinstance(m, nn.Sequential):\n",
        "                continue\n",
        "            if not len(m) in [2, 3]:  # Only handle conv-BN or conv-BN-relu\n",
        "                continue\n",
        "            #   If you use a custom Conv2d impl, assume it also has 'kernel_size' and 'weight'\n",
        "            if hasattr(m[0], 'kernel_size') and hasattr(m[0], 'weight') and isinstance(m[1], nn.BatchNorm2d):\n",
        "                conv = m[0]\n",
        "                bn = m[1]\n",
        "                fused_kernel, fused_bias = fuse_bn(conv, bn)\n",
        "                fused_conv = get_conv2d(conv.in_channels, conv.out_channels, kernel_size=conv.kernel_size,\n",
        "                                        stride=conv.stride,\n",
        "                                        padding=conv.padding, dilation=conv.dilation, groups=conv.groups, bias=True)\n",
        "                fused_conv.weight.data = fused_kernel\n",
        "                fused_conv.bias.data = fused_bias\n",
        "                m[0] = fused_conv\n",
        "                m[1] = nn.Identity()\n",
        "\n",
        "\n",
        "def create_RepLKNet31B(drop_path_rate=0.3, num_classes=1000, use_checkpoint=True, small_kernel_merged=False):\n",
        "    return RepLKNet(large_kernel_sizes=[31,29,27,13], layers=[2,2,18,2], channels=[128,256,512,1024],\n",
        "                    drop_path_rate=drop_path_rate, small_kernel=5, num_classes=num_classes, use_checkpoint=use_checkpoint,\n",
        "                    small_kernel_merged=small_kernel_merged)\n",
        "\n",
        "def create_RepLKNet31L(drop_path_rate=0.3, num_classes=1000, use_checkpoint=True, small_kernel_merged=False):\n",
        "    return RepLKNet(large_kernel_sizes=[31,29,27,13], layers=[2,2,18,2], channels=[192,384,768,1536],\n",
        "                    drop_path_rate=drop_path_rate, small_kernel=5, num_classes=num_classes, use_checkpoint=use_checkpoint,\n",
        "                    small_kernel_merged=small_kernel_merged)\n",
        "\n",
        "def create_RepLKNetXL(drop_path_rate=0.3, num_classes=1000, use_checkpoint=True, small_kernel_merged=False):\n",
        "    return RepLKNet(large_kernel_sizes=[27,27,27,13], layers=[2,2,18,2], channels=[256,512,1024,2048],\n",
        "                    drop_path_rate=drop_path_rate, small_kernel=None, dw_ratio=1.5,\n",
        "                    num_classes=num_classes, use_checkpoint=use_checkpoint,\n",
        "                    small_kernel_merged=small_kernel_merged)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    model = create_RepLKNet31B(small_kernel_merged=False)\n",
        "    model.eval()\n",
        "    print('------------------- training-time model -------------')\n",
        "    print(model)\n",
        "    x = torch.randn(2, 3, 224, 224)\n",
        "    origin_y = model(x)\n",
        "    model.structural_reparam()\n",
        "    print('------------------- after re-param -------------')\n",
        "    print(model)\n",
        "    reparam_y = model(x)\n",
        "    print('------------------- the difference is ------------------------')\n",
        "    print((origin_y - reparam_y).abs().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "179e561f",
      "metadata": {
        "id": "179e561f",
        "papermill": {
          "duration": 0.018985,
          "end_time": "2024-04-01T21:29:58.082712",
          "exception": false,
          "start_time": "2024-04-01T21:29:58.063727",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b656ea1",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-01T21:29:58.122106Z",
          "iopub.status.busy": "2024-04-01T21:29:58.121756Z",
          "iopub.status.idle": "2024-04-01T21:29:58.385844Z",
          "shell.execute_reply": "2024-04-01T21:29:58.385086Z"
        },
        "id": "2b656ea1",
        "papermill": {
          "duration": 0.287008,
          "end_time": "2024-04-01T21:29:58.388205",
          "exception": false,
          "start_time": "2024-04-01T21:29:58.101197",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "#\n",
        "# For licensing see accompanying LICENSE file.\n",
        "# Copyright (C) 2023 Apple Inc. All Rights Reserved.\n",
        "#\n",
        "import os\n",
        "import copy\n",
        "from functools import partial\n",
        "from typing import List, Tuple, Optional, Union\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def convolutional_stem(\n",
        "    in_channels: int, out_channels: int, inference_mode: bool = False\n",
        ") -> nn.Sequential:\n",
        "    \"\"\"Build convolutional stem with MobileOne blocks.\n",
        "\n",
        "    Args:\n",
        "        in_channels: Number of input channels.\n",
        "        out_channels: Number of output channels.\n",
        "        inference_mode: Flag to instantiate model in inference mode. Default: ``False``\n",
        "\n",
        "    Returns:\n",
        "        nn.Sequential object with stem elements.\n",
        "    \"\"\"\n",
        "    return nn.Sequential(\n",
        "        MobileOneBlock(\n",
        "            in_channels=in_channels,\n",
        "            out_channels=out_channels,\n",
        "            kernel_size=3,\n",
        "            stride=2,\n",
        "            padding=1,\n",
        "            groups=1,\n",
        "            inference_mode=inference_mode,\n",
        "            use_se=False,\n",
        "            num_conv_branches=1,\n",
        "        ),\n",
        "        MobileOneBlock(\n",
        "            in_channels=out_channels,\n",
        "            out_channels=out_channels,\n",
        "            kernel_size=3,\n",
        "            stride=2,\n",
        "            padding=1,\n",
        "            groups=out_channels,\n",
        "            inference_mode=inference_mode,\n",
        "            use_se=False,\n",
        "            num_conv_branches=1,\n",
        "        ),\n",
        "        MobileOneBlock(\n",
        "            in_channels=out_channels,\n",
        "            out_channels=out_channels,\n",
        "            kernel_size=1,\n",
        "            stride=1,\n",
        "            padding=0,\n",
        "            groups=1,\n",
        "            inference_mode=inference_mode,\n",
        "            use_se=False,\n",
        "            num_conv_branches=1,\n",
        "        ),\n",
        "    )\n",
        "\n",
        "\n",
        "class MHSA(nn.Module):\n",
        "    \"\"\"Multi-headed Self Attention module.\n",
        "\n",
        "    Source modified from:\n",
        "    https://github.com/rwightman/pytorch-image-models/blob/master/timm/models/vision_transformer.py\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        dim: int,\n",
        "        head_dim: int = 32,\n",
        "        qkv_bias: bool = False,\n",
        "        attn_drop: float = 0.0,\n",
        "        proj_drop: float = 0.0,\n",
        "    ) -> None:\n",
        "        \"\"\"Build MHSA module that can handle 3D or 4D input tensors.\n",
        "\n",
        "        Args:\n",
        "            dim: Number of embedding dimensions.\n",
        "            head_dim: Number of hidden dimensions per head. Default: ``32``\n",
        "            qkv_bias: Use bias or not. Default: ``False``\n",
        "            attn_drop: Dropout rate for attention tensor.\n",
        "            proj_drop: Dropout rate for projection tensor.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        assert dim % head_dim == 0, \"dim should be divisible by head_dim\"\n",
        "        self.head_dim = head_dim\n",
        "        self.num_heads = dim // head_dim\n",
        "        self.scale = head_dim**-0.5\n",
        "\n",
        "        self.qkv = nn.Linear(dim, dim * 3, bias=qkv_bias)\n",
        "        self.attn_drop = nn.Dropout(attn_drop)\n",
        "        self.proj = nn.Linear(dim, dim)\n",
        "        self.proj_drop = nn.Dropout(proj_drop)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        shape = x.shape\n",
        "        B, C, H, W = shape\n",
        "        N = H * W\n",
        "        if len(shape) == 4:\n",
        "            x = torch.flatten(x, start_dim=2).transpose(-2, -1)  # (B, N, C)\n",
        "        qkv = (\n",
        "            self.qkv(x)\n",
        "            .reshape(B, N, 3, self.num_heads, self.head_dim)\n",
        "            .permute(2, 0, 3, 1, 4)\n",
        "        )\n",
        "        q, k, v = qkv.unbind(0)  # make torchscript happy (cannot use tensor as tuple)\n",
        "\n",
        "        # trick here to make q@k.t more stable\n",
        "        attn = (q * self.scale) @ k.transpose(-2, -1)\n",
        "        attn = attn.softmax(dim=-1)\n",
        "        attn = self.attn_drop(attn)\n",
        "\n",
        "        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n",
        "        x = self.proj(x)\n",
        "        x = self.proj_drop(x)\n",
        "        if len(shape) == 4:\n",
        "            x = x.transpose(-2, -1).reshape(B, C, H, W)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class PatchEmbed(nn.Module):\n",
        "    \"\"\"Convolutional patch embedding layer.\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        patch_size: int,\n",
        "        stride: int,\n",
        "        in_channels: int,\n",
        "        embed_dim: int,\n",
        "        inference_mode: bool = False,\n",
        "    ) -> None:\n",
        "        \"\"\"Build patch embedding layer.\n",
        "\n",
        "        Args:\n",
        "            patch_size: Patch size for embedding computation.\n",
        "            stride: Stride for convolutional embedding layer.\n",
        "            in_channels: Number of channels of input tensor.\n",
        "            embed_dim: Number of embedding dimensions.\n",
        "            inference_mode: Flag to instantiate model in inference mode. Default: ``False``\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        block = list()\n",
        "        block.append(\n",
        "            ReparamLargeKernelConv(\n",
        "                in_channels=in_channels,\n",
        "                out_channels=embed_dim,\n",
        "                kernel_size=patch_size,\n",
        "                stride=stride,\n",
        "                groups=in_channels,\n",
        "                small_kernel=3,\n",
        "            )\n",
        "        )\n",
        "        block.append(\n",
        "            MobileOneBlock(\n",
        "                in_channels=embed_dim,\n",
        "                out_channels=embed_dim,\n",
        "                kernel_size=1,\n",
        "                stride=1,\n",
        "                padding=0,\n",
        "                groups=1,\n",
        "                inference_mode=inference_mode,\n",
        "                use_se=False,\n",
        "                num_conv_branches=1,\n",
        "            )\n",
        "        )\n",
        "        self.proj = nn.Sequential(*block)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.proj(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class RepMixer(nn.Module):\n",
        "    \"\"\"Reparameterizable token mixer.\n",
        "\n",
        "    For more details, please refer to our paper:\n",
        "    `FastViT: A Fast Hybrid Vision Transformer using Structural Reparameterization <https://arxiv.org/pdf/2303.14189.pdf>`_\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        dim,\n",
        "        kernel_size=3,\n",
        "        use_layer_scale=True,\n",
        "        layer_scale_init_value=1e-5,\n",
        "        inference_mode: bool = False,\n",
        "    ):\n",
        "        \"\"\"Build RepMixer Module.\n",
        "\n",
        "        Args:\n",
        "            dim: Input feature map dimension. :math:`C_{in}` from an expected input of size :math:`(B, C_{in}, H, W)`.\n",
        "            kernel_size: Kernel size for spatial mixing. Default: 3\n",
        "            use_layer_scale: If True, learnable layer scale is used. Default: ``True``\n",
        "            layer_scale_init_value: Initial value for layer scale. Default: 1e-5\n",
        "            inference_mode: If True, instantiates model in inference mode. Default: ``False``\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "        self.kernel_size = kernel_size\n",
        "        self.inference_mode = inference_mode\n",
        "\n",
        "        if inference_mode:\n",
        "            self.reparam_conv = nn.Conv2d(\n",
        "                in_channels=self.dim,\n",
        "                out_channels=self.dim,\n",
        "                kernel_size=self.kernel_size,\n",
        "                stride=1,\n",
        "                padding=self.kernel_size // 2,\n",
        "                groups=self.dim,\n",
        "                bias=True,\n",
        "            )\n",
        "        else:\n",
        "            self.norm = MobileOneBlock(\n",
        "                dim,\n",
        "                dim,\n",
        "                kernel_size,\n",
        "                padding=kernel_size // 2,\n",
        "                groups=dim,\n",
        "                use_se=False,\n",
        "                num_conv_branches=0,\n",
        "            )\n",
        "            self.mixer = MobileOneBlock(\n",
        "                dim,\n",
        "                dim,\n",
        "                kernel_size,\n",
        "                padding=kernel_size // 2,\n",
        "                groups=dim,\n",
        "                use_se=False,\n",
        "            )\n",
        "            self.use_layer_scale = use_layer_scale\n",
        "            if use_layer_scale:\n",
        "                self.layer_scale = nn.Parameter(\n",
        "                    layer_scale_init_value * torch.ones((dim, 1, 1)), requires_grad=True\n",
        "                )\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        if hasattr(self, \"reparam_conv\"):\n",
        "            x = self.reparam_conv(x)\n",
        "            return x\n",
        "        else:\n",
        "            if self.use_layer_scale:\n",
        "                x = x + self.layer_scale * (self.mixer(x) - self.norm(x))\n",
        "            else:\n",
        "                x = x + self.mixer(x) - self.norm(x)\n",
        "            return x\n",
        "\n",
        "    def reparameterize(self) -> None:\n",
        "        \"\"\"Reparameterize mixer and norm into a single\n",
        "        convolutional layer for efficient inference.\n",
        "        \"\"\"\n",
        "        if self.inference_mode:\n",
        "            return\n",
        "\n",
        "        self.mixer.reparameterize()\n",
        "        self.norm.reparameterize()\n",
        "\n",
        "        if self.use_layer_scale:\n",
        "            w = self.mixer.id_tensor + self.layer_scale.unsqueeze(-1) * (\n",
        "                self.mixer.reparam_conv.weight - self.norm.reparam_conv.weight\n",
        "            )\n",
        "            b = torch.squeeze(self.layer_scale) * (\n",
        "                self.mixer.reparam_conv.bias - self.norm.reparam_conv.bias\n",
        "            )\n",
        "        else:\n",
        "            w = (\n",
        "                self.mixer.id_tensor\n",
        "                + self.mixer.reparam_conv.weight\n",
        "                - self.norm.reparam_conv.weight\n",
        "            )\n",
        "            b = self.mixer.reparam_conv.bias - self.norm.reparam_conv.bias\n",
        "\n",
        "        self.reparam_conv = nn.Conv2d(\n",
        "            in_channels=self.dim,\n",
        "            out_channels=self.dim,\n",
        "            kernel_size=self.kernel_size,\n",
        "            stride=1,\n",
        "            padding=self.kernel_size // 2,\n",
        "            groups=self.dim,\n",
        "            bias=True,\n",
        "        )\n",
        "        self.reparam_conv.weight.data = w\n",
        "        self.reparam_conv.bias.data = b\n",
        "\n",
        "        for para in self.parameters():\n",
        "            para.detach_()\n",
        "        self.__delattr__(\"mixer\")\n",
        "        self.__delattr__(\"norm\")\n",
        "        if self.use_layer_scale:\n",
        "            self.__delattr__(\"layer_scale\")\n",
        "\n",
        "\n",
        "class ConvFFN(nn.Module):\n",
        "    \"\"\"Convolutional FFN Module.\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels: int,\n",
        "        hidden_channels: Optional[int] = None,\n",
        "        out_channels: Optional[int] = None,\n",
        "        act_layer: nn.Module = nn.GELU,\n",
        "        drop: float = 0.0,\n",
        "    ) -> None:\n",
        "        \"\"\"Build convolutional FFN module.\n",
        "\n",
        "        Args:\n",
        "            in_channels: Number of input channels.\n",
        "            hidden_channels: Number of channels after expansion. Default: None\n",
        "            out_channels: Number of output channels. Default: None\n",
        "            act_layer: Activation layer. Default: ``GELU``\n",
        "            drop: Dropout rate. Default: ``0.0``.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        out_channels = out_channels or in_channels\n",
        "        hidden_channels = hidden_channels or in_channels\n",
        "        self.conv = nn.Sequential()\n",
        "        self.conv.add_module(\n",
        "            \"conv\",\n",
        "            nn.Conv2d(\n",
        "                in_channels=in_channels,\n",
        "                out_channels=out_channels,\n",
        "                kernel_size=7,\n",
        "                padding=3,\n",
        "                groups=in_channels,\n",
        "                bias=False,\n",
        "            ),\n",
        "        )\n",
        "        self.conv.add_module(\"bn\", nn.BatchNorm2d(num_features=out_channels))\n",
        "        self.fc1 = nn.Conv2d(in_channels, hidden_channels, kernel_size=1)\n",
        "        self.act = act_layer()\n",
        "        self.fc2 = nn.Conv2d(hidden_channels, out_channels, kernel_size=1)\n",
        "        self.drop = nn.Dropout(drop)\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, m: nn.Module) -> None:\n",
        "        if isinstance(m, nn.Conv2d):\n",
        "            trunc_normal_(m.weight, std=0.02)\n",
        "            if m.bias is not None:\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.conv(x)\n",
        "        x = self.fc1(x)\n",
        "        x = self.act(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.drop(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class RepCPE(nn.Module):\n",
        "    \"\"\"Implementation of conditional positional encoding.\n",
        "\n",
        "    For more details refer to paper:\n",
        "    `Conditional Positional Encodings for Vision Transformers <https://arxiv.org/pdf/2102.10882.pdf>`_\n",
        "\n",
        "    In our implementation, we can reparameterize this module to eliminate a skip connection.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels: int,\n",
        "        embed_dim: int = 768,\n",
        "        spatial_shape: Union[int, Tuple[int, int]] = (7, 7),\n",
        "        inference_mode=False,\n",
        "    ) -> None:\n",
        "        \"\"\"Build reparameterizable conditional positional encoding\n",
        "\n",
        "        Args:\n",
        "            in_channels: Number of input channels.\n",
        "            embed_dim: Number of embedding dimensions. Default: 768\n",
        "            spatial_shape: Spatial shape of kernel for positional encoding. Default: (7, 7)\n",
        "            inference_mode: Flag to instantiate block in inference mode. Default: ``False``\n",
        "        \"\"\"\n",
        "        super(RepCPE, self).__init__()\n",
        "        if isinstance(spatial_shape, int):\n",
        "            spatial_shape = tuple([spatial_shape] * 2)\n",
        "        assert isinstance(spatial_shape, Tuple), (\n",
        "            f'\"spatial_shape\" must by a sequence or int, '\n",
        "            f\"get {type(spatial_shape)} instead.\"\n",
        "        )\n",
        "        assert len(spatial_shape) == 2, (\n",
        "            f'Length of \"spatial_shape\" should be 2, '\n",
        "            f\"got {len(spatial_shape)} instead.\"\n",
        "        )\n",
        "\n",
        "        self.spatial_shape = spatial_shape\n",
        "        self.embed_dim = embed_dim\n",
        "        self.in_channels = in_channels\n",
        "        self.groups = embed_dim\n",
        "\n",
        "        if inference_mode:\n",
        "            self.reparam_conv = nn.Conv2d(\n",
        "                in_channels=self.in_channels,\n",
        "                out_channels=self.embed_dim,\n",
        "                kernel_size=self.spatial_shape,\n",
        "                stride=1,\n",
        "                padding=int(self.spatial_shape[0] // 2),\n",
        "                groups=self.embed_dim,\n",
        "                bias=True,\n",
        "            )\n",
        "        else:\n",
        "            self.pe = nn.Conv2d(\n",
        "                in_channels,\n",
        "                embed_dim,\n",
        "                spatial_shape,\n",
        "                1,\n",
        "                int(spatial_shape[0] // 2),\n",
        "                bias=True,\n",
        "                groups=embed_dim,\n",
        "            )\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        if hasattr(self, \"reparam_conv\"):\n",
        "            x = self.reparam_conv(x)\n",
        "            return x\n",
        "        else:\n",
        "            x = self.pe(x) + x\n",
        "            return x\n",
        "\n",
        "    def reparameterize(self) -> None:\n",
        "        # Build equivalent Id tensor\n",
        "        input_dim = self.in_channels // self.groups\n",
        "        kernel_value = torch.zeros(\n",
        "            (\n",
        "                self.in_channels,\n",
        "                input_dim,\n",
        "                self.spatial_shape[0],\n",
        "                self.spatial_shape[1],\n",
        "            ),\n",
        "            dtype=self.pe.weight.dtype,\n",
        "            device=self.pe.weight.device,\n",
        "        )\n",
        "        for i in range(self.in_channels):\n",
        "            kernel_value[\n",
        "                i,\n",
        "                i % input_dim,\n",
        "                self.spatial_shape[0] // 2,\n",
        "                self.spatial_shape[1] // 2,\n",
        "            ] = 1\n",
        "        id_tensor = kernel_value\n",
        "\n",
        "        # Reparameterize Id tensor and conv\n",
        "        w_final = id_tensor + self.pe.weight\n",
        "        b_final = self.pe.bias\n",
        "\n",
        "        # Introduce reparam conv\n",
        "        self.reparam_conv = nn.Conv2d(\n",
        "            in_channels=self.in_channels,\n",
        "            out_channels=self.embed_dim,\n",
        "            kernel_size=self.spatial_shape,\n",
        "            stride=1,\n",
        "            padding=int(self.spatial_shape[0] // 2),\n",
        "            groups=self.embed_dim,\n",
        "            bias=True,\n",
        "        )\n",
        "        self.reparam_conv.weight.data = w_final\n",
        "        self.reparam_conv.bias.data = b_final\n",
        "\n",
        "        for para in self.parameters():\n",
        "            para.detach_()\n",
        "        self.__delattr__(\"pe\")\n",
        "\n",
        "\n",
        "class RepMixerBlock(nn.Module):\n",
        "    \"\"\"Implementation of Metaformer block with RepMixer as token mixer.\n",
        "\n",
        "    For more details on Metaformer structure, please refer to:\n",
        "    `MetaFormer Is Actually What You Need for Vision <https://arxiv.org/pdf/2111.11418.pdf>`_\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        dim: int,\n",
        "        kernel_size: int = 3,\n",
        "        mlp_ratio: float = 4.0,\n",
        "        act_layer: nn.Module = nn.GELU,\n",
        "        drop: float = 0.0,\n",
        "        drop_path: float = 0.0,\n",
        "        use_layer_scale: bool = True,\n",
        "        layer_scale_init_value: float = 1e-5,\n",
        "        inference_mode: bool = False,\n",
        "    ):\n",
        "        \"\"\"Build RepMixer Block.\n",
        "\n",
        "        Args:\n",
        "            dim: Number of embedding dimensions.\n",
        "            kernel_size: Kernel size for repmixer. Default: 3\n",
        "            mlp_ratio: MLP expansion ratio. Default: 4.0\n",
        "            act_layer: Activation layer. Default: ``nn.GELU``\n",
        "            drop: Dropout rate. Default: 0.0\n",
        "            drop_path: Drop path rate. Default: 0.0\n",
        "            use_layer_scale: Flag to turn on layer scale. Default: ``True``\n",
        "            layer_scale_init_value: Layer scale value at initialization. Default: 1e-5\n",
        "            inference_mode: Flag to instantiate block in inference mode. Default: ``False``\n",
        "        \"\"\"\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.token_mixer = RepMixer(\n",
        "            dim,\n",
        "            kernel_size=kernel_size,\n",
        "            use_layer_scale=use_layer_scale,\n",
        "            layer_scale_init_value=layer_scale_init_value,\n",
        "            inference_mode=inference_mode,\n",
        "        )\n",
        "\n",
        "        assert mlp_ratio > 0, \"MLP ratio should be greater than 0, found: {}\".format(\n",
        "            mlp_ratio\n",
        "        )\n",
        "        mlp_hidden_dim = int(dim * mlp_ratio)\n",
        "        self.convffn = ConvFFN(\n",
        "            in_channels=dim,\n",
        "            hidden_channels=mlp_hidden_dim,\n",
        "            act_layer=act_layer,\n",
        "            drop=drop,\n",
        "        )\n",
        "\n",
        "        # Drop Path\n",
        "        self.drop_path = DropPath(drop_path) if drop_path > 0.0 else nn.Identity()\n",
        "\n",
        "        # Layer Scale\n",
        "        self.use_layer_scale = use_layer_scale\n",
        "        if use_layer_scale:\n",
        "            self.layer_scale = nn.Parameter(\n",
        "                layer_scale_init_value * torch.ones((dim, 1, 1)), requires_grad=True\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.use_layer_scale:\n",
        "            x = self.token_mixer(x)\n",
        "            x = x + self.drop_path(self.layer_scale * self.convffn(x))\n",
        "        else:\n",
        "            x = self.token_mixer(x)\n",
        "            x = x + self.drop_path(self.convffn(x))\n",
        "        return x\n",
        "\n",
        "\n",
        "class AttentionBlock(nn.Module):\n",
        "    \"\"\"Implementation of metaformer block with MHSA as token mixer.\n",
        "\n",
        "    For more details on Metaformer structure, please refer to:\n",
        "    `MetaFormer Is Actually What You Need for Vision <https://arxiv.org/pdf/2111.11418.pdf>`_\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        dim: int,\n",
        "        mlp_ratio: float = 4.0,\n",
        "        act_layer: nn.Module = nn.GELU,\n",
        "        norm_layer: nn.Module = nn.BatchNorm2d,\n",
        "        drop: float = 0.0,\n",
        "        drop_path: float = 0.0,\n",
        "        use_layer_scale: bool = True,\n",
        "        layer_scale_init_value: float = 1e-5,\n",
        "    ):\n",
        "        \"\"\"Build Attention Block.\n",
        "\n",
        "        Args:\n",
        "            dim: Number of embedding dimensions.\n",
        "            mlp_ratio: MLP expansion ratio. Default: 4.0\n",
        "            act_layer: Activation layer. Default: ``nn.GELU``\n",
        "            norm_layer: Normalization layer. Default: ``nn.BatchNorm2d``\n",
        "            drop: Dropout rate. Default: 0.0\n",
        "            drop_path: Drop path rate. Default: 0.0\n",
        "            use_layer_scale: Flag to turn on layer scale. Default: ``True``\n",
        "            layer_scale_init_value: Layer scale value at initialization. Default: 1e-5\n",
        "        \"\"\"\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.norm = norm_layer(dim)\n",
        "        self.token_mixer = MHSA(dim=dim)\n",
        "\n",
        "        assert mlp_ratio > 0, \"MLP ratio should be greater than 0, found: {}\".format(\n",
        "            mlp_ratio\n",
        "        )\n",
        "        mlp_hidden_dim = int(dim * mlp_ratio)\n",
        "        self.convffn = ConvFFN(\n",
        "            in_channels=dim,\n",
        "            hidden_channels=mlp_hidden_dim,\n",
        "            act_layer=act_layer,\n",
        "            drop=drop,\n",
        "        )\n",
        "\n",
        "        # Drop path\n",
        "        self.drop_path = DropPath(drop_path) if drop_path > 0.0 else nn.Identity()\n",
        "\n",
        "        # Layer Scale\n",
        "        self.use_layer_scale = use_layer_scale\n",
        "        if use_layer_scale:\n",
        "            self.layer_scale_1 = nn.Parameter(\n",
        "                layer_scale_init_value * torch.ones((dim, 1, 1)), requires_grad=True\n",
        "            )\n",
        "            self.layer_scale_2 = nn.Parameter(\n",
        "                layer_scale_init_value * torch.ones((dim, 1, 1)), requires_grad=True\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.use_layer_scale:\n",
        "            x = x + self.drop_path(self.layer_scale_1 * self.token_mixer(self.norm(x)))\n",
        "            x = x + self.drop_path(self.layer_scale_2 * self.convffn(x))\n",
        "        else:\n",
        "            x = x + self.drop_path(self.token_mixer(self.norm(x)))\n",
        "            x = x + self.drop_path(self.convffn(x))\n",
        "        return x\n",
        "\n",
        "\n",
        "def basic_blocks(\n",
        "    dim: int,\n",
        "    block_index: int,\n",
        "    num_blocks: List[int],\n",
        "    token_mixer_type: str,\n",
        "    kernel_size: int = 3,\n",
        "    mlp_ratio: float = 4.0,\n",
        "    act_layer: nn.Module = nn.GELU,\n",
        "    norm_layer: nn.Module = nn.BatchNorm2d,\n",
        "    drop_rate: float = 0.0,\n",
        "    drop_path_rate: float = 0.0,\n",
        "    use_layer_scale: bool = True,\n",
        "    layer_scale_init_value: float = 1e-5,\n",
        "    inference_mode=False,\n",
        ") -> nn.Sequential:\n",
        "    \"\"\"Build FastViT blocks within a stage.\n",
        "\n",
        "    Args:\n",
        "        dim: Number of embedding dimensions.\n",
        "        block_index: block index.\n",
        "        num_blocks: List containing number of blocks per stage.\n",
        "        token_mixer_type: Token mixer type.\n",
        "        kernel_size: Kernel size for repmixer.\n",
        "        mlp_ratio: MLP expansion ratio.\n",
        "        act_layer: Activation layer.\n",
        "        norm_layer: Normalization layer.\n",
        "        drop_rate: Dropout rate.\n",
        "        drop_path_rate: Drop path rate.\n",
        "        use_layer_scale: Flag to turn on layer scale regularization.\n",
        "        layer_scale_init_value: Layer scale value at initialization.\n",
        "        inference_mode: Flag to instantiate block in inference mode.\n",
        "\n",
        "    Returns:\n",
        "        nn.Sequential object of all the blocks within the stage.\n",
        "    \"\"\"\n",
        "    blocks = []\n",
        "    for block_idx in range(num_blocks[block_index]):\n",
        "        block_dpr = (\n",
        "            drop_path_rate\n",
        "            * (block_idx + sum(num_blocks[:block_index]))\n",
        "            / (sum(num_blocks) - 1)\n",
        "        )\n",
        "        if token_mixer_type == \"repmixer\":\n",
        "            blocks.append(\n",
        "                RepMixerBlock(\n",
        "                    dim,\n",
        "                    kernel_size=kernel_size,\n",
        "                    mlp_ratio=mlp_ratio,\n",
        "                    act_layer=act_layer,\n",
        "                    drop=drop_rate,\n",
        "                    drop_path=block_dpr,\n",
        "                    use_layer_scale=use_layer_scale,\n",
        "                    layer_scale_init_value=layer_scale_init_value,\n",
        "                    inference_mode=inference_mode,\n",
        "                )\n",
        "            )\n",
        "        elif token_mixer_type == \"attention\":\n",
        "            blocks.append(\n",
        "                AttentionBlock(\n",
        "                    dim,\n",
        "                    mlp_ratio=mlp_ratio,\n",
        "                    act_layer=act_layer,\n",
        "                    norm_layer=norm_layer,\n",
        "                    drop=drop_rate,\n",
        "                    drop_path=block_dpr,\n",
        "                    use_layer_scale=use_layer_scale,\n",
        "                    layer_scale_init_value=layer_scale_init_value,\n",
        "                )\n",
        "            )\n",
        "        else:\n",
        "            raise ValueError(\n",
        "                \"Token mixer type: {} not supported\".format(token_mixer_type)\n",
        "            )\n",
        "    blocks = nn.Sequential(*blocks)\n",
        "\n",
        "    return blocks\n",
        "\n",
        "\n",
        "class FastViT(nn.Module):\n",
        "    \"\"\"\n",
        "    This class implements `FastViT architecture <https://arxiv.org/pdf/2303.14189.pdf>`_\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        layers,\n",
        "        token_mixers: Tuple[str, ...],\n",
        "        embed_dims=None,\n",
        "        mlp_ratios=None,\n",
        "        downsamples=None,\n",
        "        repmixer_kernel_size=3,\n",
        "        norm_layer: nn.Module = nn.BatchNorm2d,\n",
        "        act_layer: nn.Module = nn.GELU,\n",
        "        num_classes=1000,\n",
        "        pos_embs=None,\n",
        "        down_patch_size=7,\n",
        "        down_stride=2,\n",
        "        drop_rate=0.0,\n",
        "        drop_path_rate=0.0,\n",
        "        use_layer_scale=True,\n",
        "        layer_scale_init_value=1e-5,\n",
        "        fork_feat=False,\n",
        "        init_cfg=None,\n",
        "        pretrained=None,\n",
        "        cls_ratio=2.0,\n",
        "        inference_mode=False,\n",
        "        **kwargs,\n",
        "    ) -> None:\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        if not fork_feat:\n",
        "            self.num_classes = num_classes\n",
        "        self.fork_feat = fork_feat\n",
        "\n",
        "        if pos_embs is None:\n",
        "            pos_embs = [None] * len(layers)\n",
        "\n",
        "        # Convolutional stem\n",
        "        self.patch_embed = convolutional_stem(3, embed_dims[0], inference_mode)\n",
        "\n",
        "        # Build the main stages of the network architecture\n",
        "        network = []\n",
        "        for i in range(len(layers)):\n",
        "            # Add position embeddings if requested\n",
        "            if pos_embs[i] is not None:\n",
        "                network.append(\n",
        "                    pos_embs[i](\n",
        "                        embed_dims[i], embed_dims[i], inference_mode=inference_mode\n",
        "                    )\n",
        "                )\n",
        "            stage = basic_blocks(\n",
        "                embed_dims[i],\n",
        "                i,\n",
        "                layers,\n",
        "                token_mixer_type=token_mixers[i],\n",
        "                kernel_size=repmixer_kernel_size,\n",
        "                mlp_ratio=mlp_ratios[i],\n",
        "                act_layer=act_layer,\n",
        "                norm_layer=norm_layer,\n",
        "                drop_rate=drop_rate,\n",
        "                drop_path_rate=drop_path_rate,\n",
        "                use_layer_scale=use_layer_scale,\n",
        "                layer_scale_init_value=layer_scale_init_value,\n",
        "                inference_mode=inference_mode,\n",
        "            )\n",
        "            network.append(stage)\n",
        "            if i >= len(layers) - 1:\n",
        "                break\n",
        "\n",
        "            # Patch merging/downsampling between stages.\n",
        "            if downsamples[i] or embed_dims[i] != embed_dims[i + 1]:\n",
        "                network.append(\n",
        "                    PatchEmbed(\n",
        "                        patch_size=down_patch_size,\n",
        "                        stride=down_stride,\n",
        "                        in_channels=embed_dims[i],\n",
        "                        embed_dim=embed_dims[i + 1],\n",
        "                        inference_mode=inference_mode,\n",
        "                    )\n",
        "                )\n",
        "\n",
        "        self.network = nn.ModuleList(network)\n",
        "\n",
        "        # For segmentation and detection, extract intermediate output\n",
        "        if self.fork_feat:\n",
        "            # add a norm layer for each output\n",
        "            self.out_indices = [0, 2, 4, 6]\n",
        "            for i_emb, i_layer in enumerate(self.out_indices):\n",
        "                if i_emb == 0 and os.environ.get(\"FORK_LAST3\", None):\n",
        "                    \"\"\"For RetinaNet, `start_level=1`. The first norm layer will not used.\n",
        "                    cmd: `FORK_LAST3=1 python -m torch.distributed.launch ...`\n",
        "                    \"\"\"\n",
        "                    layer = nn.Identity()\n",
        "                else:\n",
        "                    layer = norm_layer(embed_dims[i_emb])\n",
        "                layer_name = f\"norm{i_layer}\"\n",
        "                self.add_module(layer_name, layer)\n",
        "        else:\n",
        "            # Classifier head\n",
        "            self.gap = nn.AdaptiveAvgPool2d(output_size=1)\n",
        "            self.conv_exp = MobileOneBlock(\n",
        "                in_channels=embed_dims[-1],\n",
        "                out_channels=int(embed_dims[-1] * cls_ratio),\n",
        "                kernel_size=3,\n",
        "                stride=1,\n",
        "                padding=1,\n",
        "                groups=embed_dims[-1],\n",
        "                inference_mode=inference_mode,\n",
        "                use_se=True,\n",
        "                num_conv_branches=1,\n",
        "            )\n",
        "            self.head = (\n",
        "                nn.Linear(int(embed_dims[-1] * cls_ratio), num_classes)\n",
        "                if num_classes > 0\n",
        "                else nn.Identity()\n",
        "            )\n",
        "\n",
        "        self.apply(self.cls_init_weights)\n",
        "        self.init_cfg = copy.deepcopy(init_cfg)\n",
        "\n",
        "        # load pre-trained model\n",
        "        if self.fork_feat and (self.init_cfg is not None or pretrained is not None):\n",
        "            self.init_weights()\n",
        "\n",
        "    def cls_init_weights(self, m: nn.Module) -> None:\n",
        "        \"\"\"Init. for classification\"\"\"\n",
        "        if isinstance(m, nn.Linear):\n",
        "            trunc_normal_(m.weight, std=0.02)\n",
        "            if isinstance(m, nn.Linear) and m.bias is not None:\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    @staticmethod\n",
        "    def _scrub_checkpoint(checkpoint, model):\n",
        "        sterile_dict = {}\n",
        "        for k1, v1 in checkpoint.items():\n",
        "            if k1 not in model.state_dict():\n",
        "                continue\n",
        "            if v1.shape == model.state_dict()[k1].shape:\n",
        "                sterile_dict[k1] = v1\n",
        "        return sterile_dict\n",
        "\n",
        "    def init_weights(self, pretrained: str = None) -> None:\n",
        "        \"\"\"Init. for mmdetection or mmsegmentation by loading\n",
        "        ImageNet pre-trained weights.\n",
        "        \"\"\"\n",
        "        logger = get_root_logger()\n",
        "        if self.init_cfg is None and pretrained is None:\n",
        "            logger.warning(\n",
        "                f\"No pre-trained weights for \"\n",
        "                f\"{self.__class__.__name__}, \"\n",
        "                f\"training start from scratch\"\n",
        "            )\n",
        "            pass\n",
        "        else:\n",
        "            assert \"checkpoint\" in self.init_cfg, (\n",
        "                f\"Only support \"\n",
        "                f\"specify `Pretrained` in \"\n",
        "                f\"`init_cfg` in \"\n",
        "                f\"{self.__class__.__name__} \"\n",
        "            )\n",
        "            if self.init_cfg is not None:\n",
        "                ckpt_path = self.init_cfg[\"checkpoint\"]\n",
        "            elif pretrained is not None:\n",
        "                ckpt_path = pretrained\n",
        "\n",
        "            ckpt = _load_checkpoint(ckpt_path, logger=logger, map_location=\"cpu\")\n",
        "            if \"state_dict\" in ckpt:\n",
        "                _state_dict = ckpt[\"state_dict\"]\n",
        "            elif \"model\" in ckpt:\n",
        "                _state_dict = ckpt[\"model\"]\n",
        "            else:\n",
        "                _state_dict = ckpt\n",
        "\n",
        "            sterile_dict = FastViT._scrub_checkpoint(_state_dict, self)\n",
        "            state_dict = sterile_dict\n",
        "            missing_keys, unexpected_keys = self.load_state_dict(state_dict, False)\n",
        "\n",
        "    def forward_embeddings(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.patch_embed(x)\n",
        "        return x\n",
        "\n",
        "    def forward_tokens(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        outs = []\n",
        "        for idx, block in enumerate(self.network):\n",
        "            x = block(x)\n",
        "            if self.fork_feat and idx in self.out_indices:\n",
        "                norm_layer = getattr(self, f\"norm{idx}\")\n",
        "                x_out = norm_layer(x)\n",
        "                outs.append(x_out)\n",
        "        if self.fork_feat:\n",
        "            # output the features of four stages for dense prediction\n",
        "            return outs\n",
        "        # output only the features of last layer for image classification\n",
        "        return x\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        # input embedding\n",
        "        x = self.forward_embeddings(x)\n",
        "        # through backbone\n",
        "        x = self.forward_tokens(x)\n",
        "        if self.fork_feat:\n",
        "            # output features of four stages for dense prediction\n",
        "            return x\n",
        "        # for image classification\n",
        "        x = self.conv_exp(x)\n",
        "        x = self.gap(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        cls_out = self.head(x)\n",
        "        return cls_out\n",
        "\n",
        "\n",
        "def fastvit_sa24(pretrained=False, **kwargs):\n",
        "    \"\"\"Instantiate FastViT-SA24 model variant.\"\"\"\n",
        "    layers = [4, 4, 12, 4]\n",
        "    embed_dims = [64, 128, 256, 512]\n",
        "    mlp_ratios = [4, 4, 4, 4]\n",
        "    downsamples = [True, True, True, True]\n",
        "    pos_embs = [None, None, None, partial(RepCPE, spatial_shape=(7, 7))]\n",
        "    token_mixers = (\"repmixer\", \"repmixer\", \"repmixer\", \"attention\")\n",
        "    model = FastViT(\n",
        "        layers,\n",
        "        token_mixers=token_mixers,\n",
        "        embed_dims=embed_dims,\n",
        "        pos_embs=pos_embs,\n",
        "        mlp_ratios=mlp_ratios,\n",
        "        downsamples=downsamples,\n",
        "        **kwargs,\n",
        "    )\n",
        "    if pretrained:\n",
        "        raise ValueError(\"Functionality not implemented.\")\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ae3eb0f",
      "metadata": {
        "id": "3ae3eb0f",
        "papermill": {
          "duration": 0.018146,
          "end_time": "2024-04-01T21:29:58.425264",
          "exception": false,
          "start_time": "2024-04-01T21:29:58.407118",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "### Load Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3306d11b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-01T21:29:58.463697Z",
          "iopub.status.busy": "2024-04-01T21:29:58.463128Z",
          "iopub.status.idle": "2024-04-01T21:30:06.010178Z",
          "shell.execute_reply": "2024-04-01T21:30:06.009177Z"
        },
        "id": "3306d11b",
        "papermill": {
          "duration": 7.568886,
          "end_time": "2024-04-01T21:30:06.012552",
          "exception": false,
          "start_time": "2024-04-01T21:29:58.443666",
          "status": "completed"
        },
        "tags": [],
        "outputId": "9782645d-20d7-4a4d-8b36-83d326f181d1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://github.com/facebookresearch/deit/zipball/main\" to /root/.cache/torch/hub/main.zip\n",
            "/root/.cache/torch/hub/facebookresearch_deit_main/models.py:63: UserWarning: Overwriting deit_tiny_patch16_224 in registry with models.deit_tiny_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
            "  def deit_tiny_patch16_224(pretrained=False, **kwargs):\n",
            "/root/.cache/torch/hub/facebookresearch_deit_main/models.py:78: UserWarning: Overwriting deit_small_patch16_224 in registry with models.deit_small_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
            "  def deit_small_patch16_224(pretrained=False, **kwargs):\n",
            "/root/.cache/torch/hub/facebookresearch_deit_main/models.py:93: UserWarning: Overwriting deit_base_patch16_224 in registry with models.deit_base_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
            "  def deit_base_patch16_224(pretrained=False, **kwargs):\n",
            "/root/.cache/torch/hub/facebookresearch_deit_main/models.py:108: UserWarning: Overwriting deit_tiny_distilled_patch16_224 in registry with models.deit_tiny_distilled_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
            "  def deit_tiny_distilled_patch16_224(pretrained=False, **kwargs):\n",
            "/root/.cache/torch/hub/facebookresearch_deit_main/models.py:123: UserWarning: Overwriting deit_small_distilled_patch16_224 in registry with models.deit_small_distilled_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
            "  def deit_small_distilled_patch16_224(pretrained=False, **kwargs):\n",
            "/root/.cache/torch/hub/facebookresearch_deit_main/models.py:138: UserWarning: Overwriting deit_base_distilled_patch16_224 in registry with models.deit_base_distilled_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
            "  def deit_base_distilled_patch16_224(pretrained=False, **kwargs):\n",
            "/root/.cache/torch/hub/facebookresearch_deit_main/models.py:153: UserWarning: Overwriting deit_base_patch16_384 in registry with models.deit_base_patch16_384. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
            "  def deit_base_patch16_384(pretrained=False, **kwargs):\n",
            "/root/.cache/torch/hub/facebookresearch_deit_main/models.py:168: UserWarning: Overwriting deit_base_distilled_patch16_384 in registry with models.deit_base_distilled_patch16_384. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
            "  def deit_base_distilled_patch16_384(pretrained=False, **kwargs):\n",
            "Downloading: \"https://dl.fbaipublicfiles.com/deit/deit_base_patch16_384-8de9b5d1.pth\" to /root/.cache/torch/hub/checkpoints/deit_base_patch16_384-8de9b5d1.pth\n",
            "100%|██████████| 331M/331M [00:02<00:00, 148MB/s]\n"
          ]
        }
      ],
      "source": [
        "model_fvit = fastvit_sa24()\n",
        "model = torch.hub.load('facebookresearch/deit:main', 'deit_base_patch16_384', pretrained=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "324106f9",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-01T21:30:06.057412Z",
          "iopub.status.busy": "2024-04-01T21:30:06.056665Z",
          "iopub.status.idle": "2024-04-01T21:30:06.193937Z",
          "shell.execute_reply": "2024-04-01T21:30:06.193002Z"
        },
        "id": "324106f9",
        "outputId": "de2e5243-4725-4131-9771-8821bd016a2d",
        "papermill": {
          "duration": 0.16197,
          "end_time": "2024-04-01T21:30:06.196205",
          "exception": false,
          "start_time": "2024-04-01T21:30:06.034235",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "_IncompatibleKeys(missing_keys=['network.0.0.token_mixer.norm.rbr_scale.conv.weight', 'network.0.0.token_mixer.norm.rbr_scale.bn.weight', 'network.0.0.token_mixer.norm.rbr_scale.bn.bias', 'network.0.0.token_mixer.norm.rbr_scale.bn.running_mean', 'network.0.0.token_mixer.norm.rbr_scale.bn.running_var', 'network.0.1.token_mixer.norm.rbr_scale.conv.weight', 'network.0.1.token_mixer.norm.rbr_scale.bn.weight', 'network.0.1.token_mixer.norm.rbr_scale.bn.bias', 'network.0.1.token_mixer.norm.rbr_scale.bn.running_mean', 'network.0.1.token_mixer.norm.rbr_scale.bn.running_var', 'network.0.2.token_mixer.norm.rbr_scale.conv.weight', 'network.0.2.token_mixer.norm.rbr_scale.bn.weight', 'network.0.2.token_mixer.norm.rbr_scale.bn.bias', 'network.0.2.token_mixer.norm.rbr_scale.bn.running_mean', 'network.0.2.token_mixer.norm.rbr_scale.bn.running_var', 'network.0.3.token_mixer.norm.rbr_scale.conv.weight', 'network.0.3.token_mixer.norm.rbr_scale.bn.weight', 'network.0.3.token_mixer.norm.rbr_scale.bn.bias', 'network.0.3.token_mixer.norm.rbr_scale.bn.running_mean', 'network.0.3.token_mixer.norm.rbr_scale.bn.running_var', 'network.2.0.token_mixer.norm.rbr_scale.conv.weight', 'network.2.0.token_mixer.norm.rbr_scale.bn.weight', 'network.2.0.token_mixer.norm.rbr_scale.bn.bias', 'network.2.0.token_mixer.norm.rbr_scale.bn.running_mean', 'network.2.0.token_mixer.norm.rbr_scale.bn.running_var', 'network.2.1.token_mixer.norm.rbr_scale.conv.weight', 'network.2.1.token_mixer.norm.rbr_scale.bn.weight', 'network.2.1.token_mixer.norm.rbr_scale.bn.bias', 'network.2.1.token_mixer.norm.rbr_scale.bn.running_mean', 'network.2.1.token_mixer.norm.rbr_scale.bn.running_var', 'network.2.2.token_mixer.norm.rbr_scale.conv.weight', 'network.2.2.token_mixer.norm.rbr_scale.bn.weight', 'network.2.2.token_mixer.norm.rbr_scale.bn.bias', 'network.2.2.token_mixer.norm.rbr_scale.bn.running_mean', 'network.2.2.token_mixer.norm.rbr_scale.bn.running_var', 'network.2.3.token_mixer.norm.rbr_scale.conv.weight', 'network.2.3.token_mixer.norm.rbr_scale.bn.weight', 'network.2.3.token_mixer.norm.rbr_scale.bn.bias', 'network.2.3.token_mixer.norm.rbr_scale.bn.running_mean', 'network.2.3.token_mixer.norm.rbr_scale.bn.running_var', 'network.4.0.token_mixer.norm.rbr_scale.conv.weight', 'network.4.0.token_mixer.norm.rbr_scale.bn.weight', 'network.4.0.token_mixer.norm.rbr_scale.bn.bias', 'network.4.0.token_mixer.norm.rbr_scale.bn.running_mean', 'network.4.0.token_mixer.norm.rbr_scale.bn.running_var', 'network.4.1.token_mixer.norm.rbr_scale.conv.weight', 'network.4.1.token_mixer.norm.rbr_scale.bn.weight', 'network.4.1.token_mixer.norm.rbr_scale.bn.bias', 'network.4.1.token_mixer.norm.rbr_scale.bn.running_mean', 'network.4.1.token_mixer.norm.rbr_scale.bn.running_var', 'network.4.2.token_mixer.norm.rbr_scale.conv.weight', 'network.4.2.token_mixer.norm.rbr_scale.bn.weight', 'network.4.2.token_mixer.norm.rbr_scale.bn.bias', 'network.4.2.token_mixer.norm.rbr_scale.bn.running_mean', 'network.4.2.token_mixer.norm.rbr_scale.bn.running_var', 'network.4.3.token_mixer.norm.rbr_scale.conv.weight', 'network.4.3.token_mixer.norm.rbr_scale.bn.weight', 'network.4.3.token_mixer.norm.rbr_scale.bn.bias', 'network.4.3.token_mixer.norm.rbr_scale.bn.running_mean', 'network.4.3.token_mixer.norm.rbr_scale.bn.running_var', 'network.4.4.token_mixer.norm.rbr_scale.conv.weight', 'network.4.4.token_mixer.norm.rbr_scale.bn.weight', 'network.4.4.token_mixer.norm.rbr_scale.bn.bias', 'network.4.4.token_mixer.norm.rbr_scale.bn.running_mean', 'network.4.4.token_mixer.norm.rbr_scale.bn.running_var', 'network.4.5.token_mixer.norm.rbr_scale.conv.weight', 'network.4.5.token_mixer.norm.rbr_scale.bn.weight', 'network.4.5.token_mixer.norm.rbr_scale.bn.bias', 'network.4.5.token_mixer.norm.rbr_scale.bn.running_mean', 'network.4.5.token_mixer.norm.rbr_scale.bn.running_var', 'network.4.6.token_mixer.norm.rbr_scale.conv.weight', 'network.4.6.token_mixer.norm.rbr_scale.bn.weight', 'network.4.6.token_mixer.norm.rbr_scale.bn.bias', 'network.4.6.token_mixer.norm.rbr_scale.bn.running_mean', 'network.4.6.token_mixer.norm.rbr_scale.bn.running_var', 'network.4.7.token_mixer.norm.rbr_scale.conv.weight', 'network.4.7.token_mixer.norm.rbr_scale.bn.weight', 'network.4.7.token_mixer.norm.rbr_scale.bn.bias', 'network.4.7.token_mixer.norm.rbr_scale.bn.running_mean', 'network.4.7.token_mixer.norm.rbr_scale.bn.running_var', 'network.4.8.token_mixer.norm.rbr_scale.conv.weight', 'network.4.8.token_mixer.norm.rbr_scale.bn.weight', 'network.4.8.token_mixer.norm.rbr_scale.bn.bias', 'network.4.8.token_mixer.norm.rbr_scale.bn.running_mean', 'network.4.8.token_mixer.norm.rbr_scale.bn.running_var', 'network.4.9.token_mixer.norm.rbr_scale.conv.weight', 'network.4.9.token_mixer.norm.rbr_scale.bn.weight', 'network.4.9.token_mixer.norm.rbr_scale.bn.bias', 'network.4.9.token_mixer.norm.rbr_scale.bn.running_mean', 'network.4.9.token_mixer.norm.rbr_scale.bn.running_var', 'network.4.10.token_mixer.norm.rbr_scale.conv.weight', 'network.4.10.token_mixer.norm.rbr_scale.bn.weight', 'network.4.10.token_mixer.norm.rbr_scale.bn.bias', 'network.4.10.token_mixer.norm.rbr_scale.bn.running_mean', 'network.4.10.token_mixer.norm.rbr_scale.bn.running_var', 'network.4.11.token_mixer.norm.rbr_scale.conv.weight', 'network.4.11.token_mixer.norm.rbr_scale.bn.weight', 'network.4.11.token_mixer.norm.rbr_scale.bn.bias', 'network.4.11.token_mixer.norm.rbr_scale.bn.running_mean', 'network.4.11.token_mixer.norm.rbr_scale.bn.running_var'], unexpected_keys=[])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "checkpoint = torch.load('/content/fastvit_sa24.pth.tar')\n",
        "model_fvit.load_state_dict(checkpoint['state_dict'], strict=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e30c36e",
      "metadata": {
        "id": "3e30c36e",
        "papermill": {
          "duration": 0.020849,
          "end_time": "2024-04-01T21:30:06.238531",
          "exception": false,
          "start_time": "2024-04-01T21:30:06.217682",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "### Custom Augumentation Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "366291d7",
      "metadata": {
        "id": "366291d7",
        "papermill": {
          "duration": 0.021712,
          "end_time": "2024-04-01T21:30:06.283129",
          "exception": false,
          "start_time": "2024-04-01T21:30:06.261417",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "I investigate using AHE as an augmentation method to enhance accuracy.\n",
        "\n",
        "Adaptive Histogram Equalization (AHE) is an image processing technique that enhances contrast by computing histograms for distinct image sections and redistributing lightness values. It's effective for improving local contrast and edge definition but can amplify noise in homogeneous regions. Contrast Limited Adaptive Histogram Equalization (CLAHE) addresses this issue by limiting amplification.\n",
        "\n",
        "AHE improves contrast by transforming pixels using a function derived from nearby regions, unlike standard histogram equalization. Originally developed for aircraft cockpit displays, AHE's basic approach involves transforming each pixel based on the histogram of its surrounding square. The transformation function is proportional to the cumulative distribution function (CDF) of pixel values in the neighborhood."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9cab52d6",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-01T21:30:06.326396Z",
          "iopub.status.busy": "2024-04-01T21:30:06.325713Z",
          "iopub.status.idle": "2024-04-01T21:30:06.331764Z",
          "shell.execute_reply": "2024-04-01T21:30:06.330930Z"
        },
        "id": "9cab52d6",
        "papermill": {
          "duration": 0.02967,
          "end_time": "2024-04-01T21:30:06.333717",
          "exception": false,
          "start_time": "2024-04-01T21:30:06.304047",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision.transforms.functional import equalize\n",
        "\n",
        "class EnhanceContrast(object):\n",
        "    def __call__(self, image_tensor):\n",
        "        \"\"\"\n",
        "        Enhance contrast in the input image tensor using equalization.\n",
        "\n",
        "        Args:\n",
        "            image_tensor (torch.Tensor): Input grayscale image tensor of shape (batch_size, channels, height, width).\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Output image tensor with enhanced contrast.\n",
        "        \"\"\"\n",
        "        # Convert input tensor to uint8\n",
        "        image_tensor_uint8 = (image_tensor * 255).to(torch.uint8)\n",
        "\n",
        "        # Apply equalization\n",
        "        enhanced_image_tensor = equalize(image_tensor_uint8)\n",
        "\n",
        "        return enhanced_image_tensor.float() / 255.0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c750bf10",
      "metadata": {
        "id": "c750bf10",
        "papermill": {
          "duration": 0.020446,
          "end_time": "2024-04-01T21:30:06.375034",
          "exception": false,
          "start_time": "2024-04-01T21:30:06.354588",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "I duplicate the grey scale images to three channels\n",
        "\n",
        "When utilizing neural networks pretrained with three-channel inputs, such as those expecting RGB images, grayscale images need conversion. This function, `GrayscaleToRGB`, facilitates this conversion by transforming single-channel grayscale images into three-channel RGB format. It accepts numpy arrays or torch tensors, ensuring compatibility with diverse input types. The function verifies input dimensions, ensuring they match the required (1 x H x W) shape. By replicating the grayscale image across three channels, it constructs the RGB image tensor. This process ensures seamless integration of grayscale images into networks designed for RGB inputs, enabling broader applicability and leveraging pre-existing neural network architectures."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08469143",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-01T21:30:06.419513Z",
          "iopub.status.busy": "2024-04-01T21:30:06.418744Z",
          "iopub.status.idle": "2024-04-01T21:30:06.425340Z",
          "shell.execute_reply": "2024-04-01T21:30:06.424466Z"
        },
        "id": "08469143",
        "papermill": {
          "duration": 0.030387,
          "end_time": "2024-04-01T21:30:06.427295",
          "exception": false,
          "start_time": "2024-04-01T21:30:06.396908",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "class GrayscaleToRGB(object):\n",
        "    def __call__(self, img):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            img (numpy.ndarray): Input grayscale image of shape (1 x H x W).\n",
        "\n",
        "        Returns:\n",
        "            torch.FloatTensor: RGB image tensor of shape (3 x H x W).\n",
        "        \"\"\"\n",
        "        if isinstance(img, np.ndarray):\n",
        "            img = torch.from_numpy(img)\n",
        "        if not isinstance(img, torch.Tensor):\n",
        "            raise TypeError(\"Input should be a numpy array or torch tensor.\")\n",
        "\n",
        "        if img.dim() != 3 or img.size(0) != 1:\n",
        "            raise ValueError(\"Input must be a grayscale image with shape (1 x H x W).\")\n",
        "\n",
        "        # Replicate the grayscale image across 3 channels\n",
        "        img_rgb = torch.cat((img, img, img), dim=0)\n",
        "\n",
        "        return img_rgb.float()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3661d4ac",
      "metadata": {
        "id": "3661d4ac",
        "papermill": {
          "duration": 0.021436,
          "end_time": "2024-04-01T21:30:06.469900",
          "exception": false,
          "start_time": "2024-04-01T21:30:06.448464",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "### Set up Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9bce9a67",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-01T21:30:06.514676Z",
          "iopub.status.busy": "2024-04-01T21:30:06.513761Z",
          "iopub.status.idle": "2024-04-01T21:30:06.694904Z",
          "shell.execute_reply": "2024-04-01T21:30:06.694147Z"
        },
        "id": "9bce9a67",
        "papermill": {
          "duration": 0.205563,
          "end_time": "2024-04-01T21:30:06.697115",
          "exception": false,
          "start_time": "2024-04-01T21:30:06.491552",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "from torchvision import transforms\n",
        "from torchvision import datasets as dsets\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Data augementation pipline\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((384, 384)),\n",
        "    GrayscaleToRGB(),# also does transforms.ToTensor(), # ToTensor : [0, 255] -> [0, 1]\n",
        "    #EnhanceContrast(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "def npy_loader(path):\n",
        "    sample = torch.from_numpy(np.load(path))\n",
        "    return sample\n",
        "\n",
        "train_data = dsets.DatasetFolder(\n",
        "    root=current_directory+'/dataset/train',\n",
        "    loader=npy_loader,\n",
        "    extensions=['.npy'],\n",
        "    transform=transform\n",
        ")\n",
        "test_data = dsets.DatasetFolder(\n",
        "    root=current_directory+'/dataset/val',\n",
        "    loader=npy_loader,\n",
        "    extensions=['.npy'],\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "train_data_len = len(train_data)\n",
        "test_data_len = len(test_data)\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "train_loader = DataLoader(train_data,\n",
        "                          batch_size=batch_size,\n",
        "                          shuffle=True, drop_last=True)\n",
        "\n",
        "test_loader = DataLoader(test_data,\n",
        "                         batch_size=batch_size,\n",
        "                         shuffle=True, drop_last=True)\n",
        "\n",
        "dataloaders = {\n",
        "    \"train\": train_loader,\n",
        "    \"val\": test_loader\n",
        "}\n",
        "dataset_sizes = {\n",
        "    \"train\": train_data_len,\n",
        "    \"val\": test_data_len\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa3f5725",
      "metadata": {
        "id": "aa3f5725",
        "papermill": {
          "duration": 0.020967,
          "end_time": "2024-04-01T21:30:06.740338",
          "exception": false,
          "start_time": "2024-04-01T21:30:06.719371",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "Utility function for counting files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee02515b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-01T21:30:06.785176Z",
          "iopub.status.busy": "2024-04-01T21:30:06.784652Z",
          "iopub.status.idle": "2024-04-01T21:30:06.791787Z",
          "shell.execute_reply": "2024-04-01T21:30:06.790848Z"
        },
        "id": "ee02515b",
        "outputId": "3ef05d2c-8b58-467f-c4c9-6a81b6f4ca8d",
        "papermill": {
          "duration": 0.0315,
          "end_time": "2024-04-01T21:30:06.793772",
          "exception": false,
          "start_time": "2024-04-01T21:30:06.762272",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 0 files in the folder '/content/dataset/val/sphere' and its subdirectories.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "def count_files(folder_path):\n",
        "  \"\"\"\n",
        "  This function counts the number of files in a directory and its subdirectories.\n",
        "\n",
        "  Args:\n",
        "      folder_path: The path to the directory to be traversed.\n",
        "\n",
        "  Returns:\n",
        "      An integer representing the total number of files found.\n",
        "  \"\"\"\n",
        "  total_files = 0\n",
        "  for root, _, files in os.walk(folder_path):\n",
        "    for file in files:\n",
        "      # Check if it's actually a file (not a directory or hidden file)\n",
        "      if os.path.isfile(os.path.join(root, file)):\n",
        "        total_files += 1\n",
        "  return total_files\n",
        "\n",
        "# Example usage\n",
        "folder_path = \"/content/dataset/val/sphere\"\n",
        "num_files = count_files(folder_path)\n",
        "\n",
        "print(f\"There are {num_files} files in the folder '{folder_path}' and its subdirectories.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66063459",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-01T21:30:06.882764Z",
          "iopub.status.busy": "2024-04-01T21:30:06.882404Z",
          "iopub.status.idle": "2024-04-01T21:30:07.233440Z",
          "shell.execute_reply": "2024-04-01T21:30:07.232397Z"
        },
        "id": "66063459",
        "outputId": "43b53a5c-2521-475d-f243-bb526aa09f77",
        "papermill": {
          "duration": 0.420741,
          "end_time": "2024-04-01T21:30:07.235492",
          "exception": false,
          "start_time": "2024-04-01T21:30:06.814751",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=768, out_features=512, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): Dropout(p=0.3, inplace=False)\n",
            "  (3): Linear(in_features=512, out_features=3, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "for param in model.parameters(): #freeze model\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Set uo classifier head\n",
        "n_inputs = model.head.in_features\n",
        "model.head = nn.Sequential(\n",
        "    nn.Linear(n_inputs, 512),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.3),\n",
        "    nn.Linear(512, 3)\n",
        ")\n",
        "model = model.to(device)\n",
        "print(model.head)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73463259",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-01T21:30:07.282890Z",
          "iopub.status.busy": "2024-04-01T21:30:07.282042Z",
          "iopub.status.idle": "2024-04-01T21:30:07.297584Z",
          "shell.execute_reply": "2024-04-01T21:30:07.296575Z"
        },
        "id": "73463259",
        "papermill": {
          "duration": 0.042527,
          "end_time": "2024-04-01T21:30:07.299462",
          "exception": false,
          "start_time": "2024-04-01T21:30:07.256935",
          "status": "completed"
        },
        "tags": [],
        "outputId": "f45dafae-5659-4fb2-9c9d-974e16189d2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=1024, out_features=512, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): Dropout(p=0.3, inplace=False)\n",
            "  (3): Linear(in_features=512, out_features=3, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "for param in model_fvit.parameters(): #freeze model\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Set uo classifier head\n",
        "n_inputs = 1024\n",
        "model_fvit.head = nn.Sequential(\n",
        "    nn.Linear(n_inputs, 512),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.3),\n",
        "    nn.Linear(512, 3)\n",
        ")\n",
        "#model_fvit = model_fvit.to(device)\n",
        "print(model_fvit.head)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dbcb9ed0",
      "metadata": {
        "id": "dbcb9ed0",
        "papermill": {
          "duration": 0.024187,
          "end_time": "2024-04-01T21:30:07.407394",
          "exception": false,
          "start_time": "2024-04-01T21:30:07.383207",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "### Carry out transfer learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d11eaab",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-01T21:30:07.451600Z",
          "iopub.status.busy": "2024-04-01T21:30:07.451157Z",
          "iopub.status.idle": "2024-04-02T07:59:18.910707Z",
          "shell.execute_reply": "2024-04-02T07:59:18.909752Z"
        },
        "id": "7d11eaab",
        "papermill": {
          "duration": 37751.484592,
          "end_time": "2024-04-02T07:59:18.913106",
          "exception": false,
          "start_time": "2024-04-01T21:30:07.428514",
          "status": "completed"
        },
        "tags": [],
        "outputId": "c05bed07-afe7-475b-b782-a61ec1caeca4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0/0\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/937 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "100%|██████████| 937/937 [10:31<00:00,  1.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Loss: 1.0736 Acc: 0.4019\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 234/234 [02:37<00:00,  1.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val Loss: 1.0371 Acc: 0.4591\n",
            "\n",
            "Training complete in 13m 9s\n",
            "Best Val Acc: 0.4591\n",
            "Epoch 0/17\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [31:34<00:00,  2.02s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Loss: 1.0289 Acc: 0.4581\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 234/234 [02:38<00:00,  1.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val Loss: 1.0122 Acc: 0.4779\n",
            "\n",
            "Epoch 1/17\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [31:35<00:00,  2.02s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Loss: 1.0071 Acc: 0.4740\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 234/234 [02:38<00:00,  1.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val Loss: 0.9947 Acc: 0.4904\n",
            "\n",
            "Epoch 2/17\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [31:34<00:00,  2.02s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Loss: 0.9946 Acc: 0.4844\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 234/234 [02:38<00:00,  1.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val Loss: 0.9844 Acc: 0.4899\n",
            "\n",
            "Epoch 3/17\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [31:35<00:00,  2.02s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Loss: 0.9853 Acc: 0.4918\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 234/234 [02:37<00:00,  1.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val Loss: 0.9800 Acc: 0.4995\n",
            "\n",
            "Epoch 4/17\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [31:34<00:00,  2.02s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Loss: 0.9774 Acc: 0.5000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 234/234 [02:37<00:00,  1.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val Loss: 0.9777 Acc: 0.4840\n",
            "\n",
            "Epoch 5/17\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [31:35<00:00,  2.02s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Loss: 0.9720 Acc: 0.5051\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 234/234 [02:37<00:00,  1.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val Loss: 0.9638 Acc: 0.5143\n",
            "\n",
            "Epoch 6/17\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [31:35<00:00,  2.02s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Loss: 0.9654 Acc: 0.5109\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 234/234 [02:37<00:00,  1.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val Loss: 0.9648 Acc: 0.5112\n",
            "\n",
            "Epoch 7/17\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [31:35<00:00,  2.02s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Loss: 0.9612 Acc: 0.5118\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 234/234 [02:38<00:00,  1.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val Loss: 0.9604 Acc: 0.5067\n",
            "\n",
            "Epoch 8/17\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [31:35<00:00,  2.02s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Loss: 0.9559 Acc: 0.5208\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 234/234 [02:38<00:00,  1.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val Loss: 0.9518 Acc: 0.5228\n",
            "\n",
            "Epoch 9/17\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [31:34<00:00,  2.02s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Loss: 0.9543 Acc: 0.5177\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 234/234 [02:38<00:00,  1.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val Loss: 0.9491 Acc: 0.5213\n",
            "\n",
            "Epoch 10/17\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [31:35<00:00,  2.02s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Loss: 0.9494 Acc: 0.5241\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 234/234 [02:38<00:00,  1.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val Loss: 0.9417 Acc: 0.5301\n",
            "\n",
            "Epoch 11/17\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [31:34<00:00,  2.02s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Loss: 0.9439 Acc: 0.5289\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 234/234 [02:38<00:00,  1.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val Loss: 0.9446 Acc: 0.5260\n",
            "\n",
            "Epoch 12/17\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [31:35<00:00,  2.02s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Loss: 0.9412 Acc: 0.5326\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 234/234 [02:38<00:00,  1.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val Loss: 0.9511 Acc: 0.5237\n",
            "\n",
            "Epoch 13/17\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [31:36<00:00,  2.02s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Loss: 0.9396 Acc: 0.5312\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 234/234 [02:38<00:00,  1.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val Loss: 0.9387 Acc: 0.5271\n",
            "\n",
            "Epoch 14/17\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [31:35<00:00,  2.02s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Loss: 0.9348 Acc: 0.5361\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 234/234 [02:38<00:00,  1.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val Loss: 0.9350 Acc: 0.5288\n",
            "\n",
            "Epoch 15/17\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [31:34<00:00,  2.02s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Loss: 0.9336 Acc: 0.5362\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 234/234 [02:38<00:00,  1.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val Loss: 0.9323 Acc: 0.5421\n",
            "\n",
            "Epoch 16/17\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [31:35<00:00,  2.02s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Loss: 0.9304 Acc: 0.5404\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 234/234 [02:38<00:00,  1.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val Loss: 0.9285 Acc: 0.5404\n",
            "\n",
            "Epoch 17/17\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [31:36<00:00,  2.02s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Loss: 0.9291 Acc: 0.5387\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 234/234 [02:38<00:00,  1.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val Loss: 0.9339 Acc: 0.5363\n",
            "\n",
            "Training complete in 616m 2s\n",
            "Best Val Acc: 0.5421\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from torch import nn, optim\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "criterion = criterion.to(device)\n",
        "optimizer = optim.Adam(model.head.parameters(), lr=0.0001)\n",
        "\n",
        "# lr scheduler\n",
        "exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.97)\n",
        "\n",
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=18):\n",
        "    since = time.time()\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
        "        print(\"-\"*10)\n",
        "\n",
        "        for phase in ['train', 'val']: # We do training and validation phase per epoch\n",
        "            if phase == 'train':\n",
        "                model.train() # model to training mode\n",
        "            else:\n",
        "                model.eval() # model to evaluate\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0.0\n",
        "\n",
        "            for inputs, labels in tqdm(dataloaders[phase]):\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                with torch.set_grad_enabled(phase == 'train'): # no autograd makes validation go faster\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1) # used for accuracy\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            if phase == 'train':\n",
        "                scheduler.step() # step at end of epoch\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc =  running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print(\"{} Loss: {:.4f} Acc: {:.4f}\".format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict()) # keep the best validation accuracy model\n",
        "        print()\n",
        "    time_elapsed = time.time() - since # slight error\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print(\"Best Val Acc: {:.4f}\".format(best_acc))\n",
        "\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model\n",
        "\n",
        "# The first epoch serves to initialize the fully connected layers properly to prevent weight destruction\n",
        "model_ft = train_model(model, criterion, optimizer, exp_lr_scheduler,num_epochs=1)\n",
        "for param in model.parameters(): # During fine-tune\n",
        "    param.requires_grad = True\n",
        "model_ft = train_model(model, criterion, optimizer, exp_lr_scheduler)\n",
        "torch.save(model_ft, current_directory+'/model_deit.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d6c6caa",
      "metadata": {
        "id": "3d6c6caa",
        "papermill": {
          "duration": 1.789464,
          "end_time": "2024-04-02T07:59:22.758008",
          "exception": false,
          "start_time": "2024-04-02T07:59:20.968544",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# Notes:\n",
        "For final training i decided to skip training Fast VIT due to lack of time and GPU hours. However, I will check back with it hopefully during GSOC as it holds a lot of promise\n",
        "\n",
        "At final training I suspended Local contrasting (AHE). After viewing the image output I found out that great care has to be taken to avoid noise amplifications and edge signal distortion. I hope to further investigate that during GSOC (hopefully I get selected).\n",
        "During training, its accuracy lags the control. I don't know if things will change after several epochs because maybe the raw image benefits more from Imagenet pretraining. I hope to investigate that. Due to lack of GPU usage hours I could not afford to train for longer periods to extensively test these things and make a full conclusion.\n",
        "\n",
        "For the DeiT model, training ends at accuracy of 54% for the same reasons as above; running out of GPU hours. However note that the train accuracy is approximatly equal and for many epochs, val accuracy goes slightly ahead of train accuracy.\n",
        "\n",
        "This shows that model has not yet saturated and holds great potential. For val to be higher than train, it means that regularization is working extremely well and the model is learning the right features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4689e2fa",
      "metadata": {
        "papermill": {
          "duration": 1.797951,
          "end_time": "2024-04-02T07:59:26.577968",
          "exception": false,
          "start_time": "2024-04-02T07:59:24.780017",
          "status": "completed"
        },
        "tags": [],
        "id": "4689e2fa"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "WY7V0Ep1UA5z",
        "fBqJlKkHWLs4",
        "sVzAT-ZcXojH"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 30674,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 37860.399,
      "end_time": "2024-04-02T07:59:30.391620",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2024-04-01T21:28:29.992620",
      "version": "2.5.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}